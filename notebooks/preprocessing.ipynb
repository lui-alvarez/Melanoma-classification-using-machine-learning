{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../helpers/')\n",
    "\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import natsort\n",
    "import cv2\n",
    "import csv\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# importing packages\n",
    "from preprocessing import Preprocessing\n",
    "from feature_extraction import FeatureExtraction\n",
    "\n",
    "preprocessor = Preprocessing()\n",
    "feature_extractor = FeatureExtraction()\n",
    "\n",
    "# To allow auto reload to this notebook after modifying any external file imported\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\master\\udg\\CAD\\project\\notebooks\\..\\challenge1\\train\n"
     ]
    }
   ],
   "source": [
    "# SAVE_PATH = Path(\"Processed-Heart-Detection\")\n",
    "# dcm_path = ROOT_PATH/str(patient_id) # joining paths\n",
    "# dcm_path = dcm_path.with_suffix(\".dcm\") # adds suffix\n",
    "\n",
    "ROOT_PATH = Path(Path(os.getcwd())/\"../challenge1\")\n",
    "TRAIN_PATH = ROOT_PATH/\"train\"\n",
    "VAL_PATH = ROOT_PATH/\"val\"\n",
    "\n",
    "print(TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nevus = sorted(glob(str(TRAIN_PATH/'nevus/*')))\n",
    "train_others = sorted(glob(str(TRAIN_PATH/'others/*')))\n",
    "\n",
    "val_nevus = sorted(glob(str(VAL_PATH/'nevus/*')))\n",
    "val_others = sorted(glob(str(VAL_PATH/'others/*')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_nevus\n",
    "\n",
    "# TODO ASK:\n",
    "# Do we normalize the images in pre-processing or after we extract all of the features?\n",
    "# Should we remove the hair? Aggressivly? \n",
    "# Should we fill the borders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img(image, gray=False):\n",
    "    if gray:\n",
    "        plt.imshow(image, cmap='gray')\n",
    "    else:\n",
    "        # plt.imshow(image)\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\master\\udg\\CAD\\project\\notebooks\\..\\output\n",
      "evus_train_features.pkl\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()+'\\..\\output\\nevus_train_features.pkl'\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing and feature extraction\n",
    "features_dir = r'../output/features/'\n",
    "\n",
    "experiment              = 2\n",
    "subsample               = True\n",
    "\n",
    "nevus_train_filename    = f'{experiment}_nevus_train_features.csv'\n",
    "nevus_val_filename      = f'{experiment}_nevus_val_features.csv'\n",
    "\n",
    "others_train_filename   = f'{experiment}_others_train_features.csv'\n",
    "others_val_filename     = f'{experiment}_others_val_features.csv'\n",
    "\n",
    "#preprocessed_images_filename = Path(os.getcwd())/'output/preprocessed_images.pkl'\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(train_nevus)\n",
    "random.shuffle(val_nevus)\n",
    "random.shuffle(train_others)\n",
    "random.shuffle(val_others)\n",
    "\n",
    "\n",
    "filenames_list = [nevus_train_filename, nevus_val_filename, others_train_filename,  others_val_filename]\n",
    "dir_list = [train_nevus, val_nevus, train_others, val_others]\n",
    "\n",
    "labels = [0, 0, 1, 1]\n",
    "\n",
    "preprocessed_images = []\n",
    "\n",
    "for index, filename in enumerate(filenames_list):\n",
    "    with open(os.path.join(features_dir, filename), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        for count, image_path in tqdm(enumerate(dir_list[index])):\n",
    "\n",
    "            if subsample:\n",
    "                if count == 999: # only 1k per class\n",
    "                    break\n",
    "\n",
    "            # reading the image \n",
    "            image = cv2.imread(image_path,cv2.IMREAD_COLOR)\n",
    "\n",
    "            # 1. Copping black frame\n",
    "            image_without_black_frame, _ = preprocessor.crop_frame(image)\n",
    "\n",
    "            # 2. Resizing\n",
    "            image_resized = preprocessor.resize_images(image_without_black_frame, preserve_ratio=True)\n",
    "\n",
    "            # 3. Removing hair\n",
    "            image_without_hair = preprocessor.extract_hair(image_resized)\n",
    "\n",
    "            # Saving the preprocessed image to a list\n",
    "            preprocessed_images.append(image_without_hair)\n",
    "\n",
    "            # 4. Displaying result\n",
    "            # display_img(image_without_hair)\n",
    "            \n",
    "            # 5. Extracting features\n",
    "            feature_vector = feature_extractor.fit(image_without_hair)\n",
    "\n",
    "            # 6. Add label column\n",
    "            feature_vector = np.append(feature_vector,labels[index])\n",
    "\n",
    "            # print(feature_vector)\n",
    "            writer.writerow(feature_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving pickles of preprocessing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing and feature extraction\n",
    "prep_imgs_dir = r'../output/'\n",
    "\n",
    "nevus_train_prep_filename    = 'nevus_train_prep_images.pkl'\n",
    "nevus_val_prep_filename      = 'nevus_val_prep_images.pkl'\n",
    "\n",
    "others_train_prep_filename   = 'others_train_prep_images.pkl'\n",
    "others_val_prep_filename     = 'others_val_prep_images.pkl'\n",
    "\n",
    "\n",
    "filenames_prep_list = [nevus_train_prep_filename, nevus_val_prep_filename, others_train_prep_filename,  others_val_prep_filename]\n",
    "dir_list = [train_nevus, val_nevus, train_others, val_others]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample               = False\n",
    "\n",
    "for index, filename in enumerate(filenames_prep_list):\n",
    "\n",
    "    preprocessed_images = []\n",
    "\n",
    "    for count, image_path in tqdm(enumerate(dir_list[index])):\n",
    "\n",
    "        if subsample:\n",
    "            if count == 999: # only 1k per class\n",
    "                break\n",
    "\n",
    "        # reading the image \n",
    "        image = cv2.imread(image_path,cv2.IMREAD_COLOR)\n",
    "\n",
    "        # 1. Copping black frame\n",
    "        image_without_black_frame, _ = preprocessor.crop_frame(image)\n",
    "\n",
    "        # 2. Resizing\n",
    "        image_resized = preprocessor.resize_images(image_without_black_frame, preserve_ratio=True)\n",
    "\n",
    "        # 3. Removing hair\n",
    "        image_without_hair = preprocessor.extract_hair(image_resized)\n",
    "\n",
    "        # Saving the preprocessed image to a list\n",
    "        preprocessed_images.append(image_without_hair)\n",
    "\n",
    "    # Saving the preprocessed images to a file\n",
    "    with open(prep_imgs_dir+filename, 'wb') as file:\n",
    "        pickle.dump(preprocessed_images, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction from saved images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 3_nevus_train_features.csv: 7725it [1:46:51,  1.20it/s]\n",
      "Processing 3_nevus_val_features.csv: 1931it [33:07,  1.03s/it]\n",
      "Processing 3_others_train_features.csv: 7470it [2:47:59,  1.35s/it]\n",
      "Processing 3_others_val_features.csv: 1865it [36:33,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing and feature extraction\n",
    "features_dir = r'../output/features/'\n",
    "\n",
    "experiment              = 3\n",
    "subsample               = False\n",
    "\n",
    "nevus_train_filename    = f'{experiment}_nevus_train_features.csv'\n",
    "nevus_val_filename      = f'{experiment}_nevus_val_features.csv'\n",
    "\n",
    "others_train_filename   = f'{experiment}_others_train_features.csv'\n",
    "others_val_filename     = f'{experiment}_others_val_features.csv'\n",
    "\n",
    "filenames_list = [nevus_train_filename, nevus_val_filename, others_train_filename, others_val_filename]\n",
    "#images_lists = [nevus_train_prep_images, nevus_val_prep_images, others_train_prep_images, others_val_prep_images]\n",
    "\n",
    "labels = [0, 0, 1, 1]\n",
    "\n",
    "\n",
    "for pickle_filename, filename, label in zip(filenames_prep_list, filenames_list, labels):\n",
    "    pickle_path = os.path.join(prep_imgs_dir, pickle_filename)\n",
    "\n",
    "    with open(pickle_path, 'rb') as file:\n",
    "        # Use a generator to load and yield images one at a time\n",
    "        def image_generator():\n",
    "            count = 0\n",
    "            try:\n",
    "                while True:\n",
    "                    image_list = pickle.load(file)\n",
    "                    for image in image_list:\n",
    "                        yield image\n",
    "                        count += 1\n",
    "                        if subsample and count == 999:  # Only 1k per class\n",
    "                            return\n",
    "            except EOFError:\n",
    "                pass\n",
    "\n",
    "        with open(os.path.join(features_dir, filename), 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "\n",
    "            count = 0\n",
    "            for preprocessed_image in tqdm(image_generator(), desc=f\"Processing {filename}\"):\n",
    "                if subsample and count == 9:  # Only 1k per class\n",
    "                    break\n",
    "\n",
    "                # 5. Extracting features\n",
    "                feature_vector = feature_extractor.fit(preprocessed_image)\n",
    "\n",
    "                # 6. Add label column\n",
    "                feature_vector = np.append(feature_vector, label)\n",
    "\n",
    "                # Write the feature vector to the CSV file\n",
    "                writer.writerow(feature_vector)\n",
    "\n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image augmentation\n",
    "# 1. Create dataset class (DL)\n",
    "# 2. pass the augmentation as an argument (create class/file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
