{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import sys\n",
    "sys.path.append('../helpers/')\n",
    "\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import natsort\n",
    "import cv2\n",
    "import csv\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# importing packages\n",
    "from preprocessing import Preprocessing\n",
    "from feature_extraction import FeatureExtraction\n",
    "\n",
    "preprocessor = Preprocessing()\n",
    "feature_extractor = FeatureExtraction()\n",
    "\n",
    "# To allow auto reload to this notebook after modifying any external file imported\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = Path(Path(os.getcwd())/\"../challenge2\")\n",
    "TRAIN_PATH = ROOT_PATH/\"train\"\n",
    "VAL_PATH = ROOT_PATH/\"val\"\n",
    "\n",
    "train_bcc = sorted(glob(str(TRAIN_PATH/'bcc/*')))\n",
    "train_mel = sorted(glob(str(TRAIN_PATH/'mel/*')))\n",
    "train_scc = sorted(glob(str(TRAIN_PATH/'scc/*')))\n",
    "\n",
    "val_bcc = sorted(glob(str(VAL_PATH/'bcc/*')))\n",
    "val_mel = sorted(glob(str(VAL_PATH/'mel/*')))\n",
    "val_scc = sorted(glob(str(VAL_PATH/'scc/*')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVING PICKLES OF PREPROCESSED IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing and feature extraction\n",
    "prep_imgs_dir = r'../output/'\n",
    "\n",
    "bcc_train_prep_filename    = 'bcc_train_prep_images.pkl'\n",
    "bcc_val_prep_filename      = 'bcc_val_prep_images.pkl'\n",
    "\n",
    "mel_train_prep_filename   = 'mel_train_prep_images.pkl'\n",
    "mel_val_prep_filename     = 'mel_val_prep_images.pkl'\n",
    "\n",
    "scc_train_prep_filename   = 'scc_train_prep_images.pkl'\n",
    "scc_val_prep_filename     = 'scc_val_prep_images.pkl'\n",
    "\n",
    "\n",
    "filenames_prep_list = [bcc_train_prep_filename, bcc_val_prep_filename, mel_train_prep_filename,  mel_val_prep_filename, scc_train_prep_filename, scc_val_prep_filename]\n",
    "dir_list = [train_bcc, val_bcc, train_mel, val_mel, train_scc, val_scc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample               = False\n",
    "\n",
    "for index, filename in enumerate(filenames_prep_list):\n",
    "\n",
    "    preprocessed_images = []\n",
    "\n",
    "    for count, image_path in tqdm(enumerate(dir_list[index])):\n",
    "\n",
    "        if subsample:\n",
    "            if count == 999: # only 1k per class\n",
    "                break\n",
    "\n",
    "        # reading the image \n",
    "        image = cv2.imread(image_path,cv2.IMREAD_COLOR)\n",
    "\n",
    "        # 1. Copping black frame\n",
    "        image_without_black_frame, _ = preprocessor.crop_frame(image)\n",
    "\n",
    "        # 2. Resizing\n",
    "        image_resized = preprocessor.resize_images(image_without_black_frame, preserve_ratio=True)\n",
    "\n",
    "        # 3. Removing hair\n",
    "        image_without_hair = preprocessor.extract_hair(image_resized)\n",
    "\n",
    "        # Saving the preprocessed image to a list\n",
    "        preprocessed_images.append(image_without_hair)\n",
    "\n",
    "    # Saving the preprocessed images to a file\n",
    "    with open(prep_imgs_dir+filename, 'wb') as file:\n",
    "        pickle.dump(preprocessed_images, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRACTING FEATURES FROM PREPROCESSED IMAGES SAVED IN PICKLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING PICKLES \n",
    "\n",
    "with open(os.path.join(prep_imgs_dir, mel_train_prep_filename), 'rb') as file:\n",
    "    mel_train_prep_images = pickle.load(file)\n",
    "with open(os.path.join(prep_imgs_dir, mel_val_prep_filename), 'rb') as file:\n",
    "    mel_val_prep_images = pickle.load(file)\n",
    "\n",
    "with open(os.path.join(prep_imgs_dir, bcc_train_prep_filename), 'rb') as file:\n",
    "    bcc_train_prep_images = pickle.load(file)\n",
    "with open(os.path.join(prep_imgs_dir, bcc_val_prep_filename), 'rb') as file:\n",
    "    bcc_val_prep_images = pickle.load(file)\n",
    "\n",
    "with open(os.path.join(prep_imgs_dir, scc_train_prep_filename), 'rb') as file:\n",
    "    scc_train_prep_images = pickle.load(file)\n",
    "with open(os.path.join(prep_imgs_dir, scc_val_prep_filename), 'rb') as file:\n",
    "    scc_val_prep_images = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1993it [54:08,  1.63s/it]\n",
      "498it [11:00,  1.33s/it]\n",
      "2713it [58:16,  1.29s/it]\n",
      "678it [15:59,  1.42s/it]\n",
      "376it [08:44,  1.40s/it]\n",
      "94it [02:22,  1.52s/it]\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing and feature extraction\n",
    "features_dir = r'../output/features/'\n",
    "\n",
    "experiment              = 1\n",
    "subsample               = False\n",
    "\n",
    "bcc_train_filename    = f'{experiment}_bcc_train_features.csv'\n",
    "bcc_val_filename      = f'{experiment}_bcc_val_features.csv'\n",
    "\n",
    "mel_train_filename    = f'{experiment}_mel_train_features.csv'\n",
    "mel_val_filename      = f'{experiment}_mel_val_features.csv'\n",
    "\n",
    "scc_train_filename   = f'{experiment}_scc_train_features.csv'\n",
    "scc_val_filename     = f'{experiment}_scc_val_features.csv'\n",
    "\n",
    "filenames_list = [bcc_train_filename, bcc_val_filename, mel_train_filename, mel_val_filename, scc_train_filename, scc_val_filename]\n",
    "images_lists = [bcc_train_prep_images, bcc_val_prep_images, mel_train_prep_images, mel_val_prep_images, scc_train_prep_images, scc_val_prep_images]\n",
    "\n",
    "labels = [0, 0, 1, 1, 2, 2] # bcc = 0, mel = 1, scc = 2\n",
    "\n",
    "\n",
    "# Loop through the lists of images and their corresponding filenames\n",
    "for filename, image_list, label in zip(filenames_list, images_lists, labels):\n",
    "    with open(os.path.join(features_dir, filename), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        for count, preprocessed_image in tqdm(enumerate(image_list)):\n",
    "            if subsample and count == 9:  # Only 1k per class\n",
    "                break\n",
    "\n",
    "            # 5. Extracting features\n",
    "            feature_vector = feature_extractor.fit(preprocessed_image)\n",
    "\n",
    "            # 6. Add label column\n",
    "            feature_vector = np.append(feature_vector, label)\n",
    "\n",
    "            # Write the feature vector to the CSV file\n",
    "            writer.writerow(feature_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPARING THE DATA FOR MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, f1_score, multilabel_confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "\n",
    "from feature_selection import FeatureSelection\n",
    "\n",
    "import pprint\n",
    "\n",
    "select_feature = FeatureSelection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dir = r'../output/features/'\n",
    "experiment              = 1\n",
    "\n",
    "train_bcc_df = pd.read_csv(os.path.join(features_dir,f'{experiment}_bcc_train_features.csv'),  header = None)\n",
    "val_bcc_df = pd.read_csv(os.path.join(features_dir, f'{experiment}_bcc_val_features.csv'),  header = None)\n",
    "\n",
    "train_mel_df = pd.read_csv(os.path.join(features_dir,f'{experiment}_mel_train_features.csv'),  header = None)\n",
    "val_mel_df = pd.read_csv(os.path.join(features_dir, f'{experiment}_mel_val_features.csv'),  header = None)\n",
    "\n",
    "train_scc_df = pd.read_csv(os.path.join(features_dir,f'{experiment}_scc_train_features.csv'),  header = None)\n",
    "val_scc_df = pd.read_csv(os.path.join(features_dir, f'{experiment}_scc_val_features.csv'),  header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the 'bcc', 'mel' and 'scc' dataframes\n",
    "train_features = pd.concat([train_bcc_df, train_mel_df, train_scc_df], ignore_index=True)\n",
    "val_features = pd.concat([val_bcc_df, val_mel_df, val_scc_df], ignore_index=True)\n",
    "\n",
    "# Shuffle the dataset\n",
    "train_features = train_features.sample(frac=1, random_state=42)\n",
    "val_features = val_features.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_features.iloc[:,:-1]\n",
    "y_train = train_features.iloc[:,-1]\n",
    "\n",
    "X_val = val_features.iloc[:,:-1]\n",
    "y_val = val_features.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the label column\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_val_encoded = encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OVERSAMPLING WITH ADASYN\n",
    "adasyn = ADASYN(sampling_strategy='not majority', random_state=0) # resample all classes but majority\n",
    "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train, y_train_encoded)\n",
    "# UNDERSAMPLING WITH TOMEK LINKS\n",
    "tomek = TomekLinks()\n",
    "X_train_tomek, y_train_tomek = tomek.fit_resample(X_train_adasyn, y_train_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the training data (mean = 0, std = 1)\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = pd.DataFrame(scaler.fit_transform(X_train_tomek))\n",
    "X_val_normalized = pd.DataFrame(scaler.transform(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_normalized.shape: (7585, 92)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_normalized.shape: {X_train_normalized.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the class unbalance before resampling techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_class_distribution_bar_chart(dataframe, title=\"Class Distribution Bar Chart\"):\n",
    "    \"\"\"\n",
    "    Create a bar chart to visualize the distribution of classes in the last column of a Pandas DataFrame with titles for each class.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe: Pandas DataFrame containing the data.\n",
    "    - title: Title for the bar chart (optional).\n",
    "\n",
    "    Returns:\n",
    "    - None (displays the class distribution bar chart with titles).\n",
    "    \"\"\"\n",
    "    # Extract the last column (class labels)\n",
    "    class_labels = dataframe.iloc[:, -1]\n",
    "\n",
    "    # Count the occurrences of each class\n",
    "    class_counts = class_labels.value_counts()\n",
    "\n",
    "    # Create the bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = class_counts.plot(kind='bar')\n",
    "    \n",
    "    # Set chart title and labels\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    \n",
    "    # Add titles to each class column\n",
    "    for i, count in enumerate(class_counts):\n",
    "        ax.text(i, count, str(count), ha='center', va='bottom')\n",
    "\n",
    "    # Display the chart\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of training data is: 5082 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1sAAAIrCAYAAAAZaYNwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABLXElEQVR4nO3deVyU5f7/8feALIosLqxHRHHFtcI0NLdUkMz0aNniSbNcStDUUqOv5XbKjlaW5pInE885+sv0ZJkWinsp7pFr5kZUCpoGqCkoc//+6Mt8G0EF5HZAXs/HYx4P57quue7PPcyMvLnv+xqLYRiGAAAAAAAlysnRBQAAAADAnYiwBQAAAAAmIGwBAAAAgAkIWwAAAABgAsIWAAAAAJiAsAUAAAAAJiBsAQAAAIAJCFsAAAAAYALCFgAAAACYgLAFoFyoVauWnn76aUeXcdtNmDBBFovFru12PRcpKSmyWCyKj4+3tT399NOqXLmy6dvOY7FYNGHChNu2vTxm7ee0adMUGhoqZ2dn3XXXXSU+PwovPj5eFotFKSkptrYOHTqoQ4cODqsJQOlD2AJQph07dkxDhgxRaGio3N3d5eXlpTZt2ui9997TpUuXHF3eHePLL790SGgpjNJcW0las2aNxowZozZt2mjBggV64403HF0SAOAmKji6AAAorlWrVunRRx+Vm5ub+vXrpyZNmignJ0fffPONRo8erQMHDmjevHmOLrPUOXz4sJyciva3ti+//FKzZs0qUqgJCQnRpUuX5OLiUsQKi+ZGtV26dEkVKtwZ/9WtX79eTk5Omj9/vlxdXR1dDgqwZs0aR5cAoJS5M/4HAlDunDhxQo8//rhCQkK0fv16BQYG2vpiYmJ09OhRrVq1yoEVll5ubm6mzn/16lVZrVa5urrK3d3d1G3djKO3X5JOnz6tihUrlljQMgxDly9fVsWKFUtkPrPnLQsIwQCuxWmEAMqkqVOn6sKFC5o/f75d0MpTt25dvfDCC9d9/Llz5/TSSy+padOmqly5sry8vBQdHa3vvvsu39iZM2eqcePGqlSpkqpUqaIWLVpo8eLFtv7z589rxIgRqlWrltzc3OTn56cuXbpoz549dvNs375dXbt2lbe3typVqqT27dtry5YtdmMKO1dBvvnmG917771yd3dXnTp19MEHHxQ47tprtq5cuaKJEyeqXr16cnd3V7Vq1XT//fcrMTFR0h/XH82aNUvSH9dA5d2k/7su66233tK7776rOnXqyM3NTQcPHizwmq08x48fV1RUlDw8PBQUFKRJkybJMAxb/8aNG2WxWLRx40a7x107541qy2u79ojXt99+q+joaHl5ealy5crq1KmTtm3bZjcm73qcLVu2aNSoUfL19ZWHh4f++te/6syZMwX/AApws/2UJKvVqnfffVeNGzeWu7u7/P39NWTIEP322292+7FgwQJdvHjRto95z8HVq1c1efJk23Nfq1YtvfLKK8rOzrbbTq1atfTQQw9p9erVatGihSpWrGh7jWRkZGjEiBEKDg6Wm5ub6tatq3/84x+yWq033ceSmPfjjz9WeHi4PD095eXlpaZNm+q9996z9Rf2/Zr3uvnkk080ceJE/eUvf5Gnp6ceeeQRZWZmKjs7WyNGjJCfn58qV66sAQMG5HueLBaLYmNjtWjRIjVo0EDu7u4KDw/X5s2bb/pcXHvN1p/ref3111WjRg25u7urU6dOOnr0aL7Hz5o1S6GhoapYsaJatmypr7/+muvAgDKOI1sAyqQvvvhCoaGhat26dbEef/z4cX322Wd69NFHVbt2baWnp+uDDz5Q+/btdfDgQQUFBUmS/vnPf2r48OF65JFH9MILL+jy5cvau3evtm/frieffFKS9Nxzz2nZsmWKjY1Vo0aNdPbsWX3zzTc6dOiQ7rnnHkl/nAIWHR2t8PBwjR8/Xk5OTlqwYIEeeOABff3112rZsmWh5yrIvn37FBkZKV9fX02YMEFXr17V+PHj5e/vf9PnYsKECZoyZYoGDhyoli1bKisrS7t27dKePXvUpUsXDRkyRCdPnlRiYqL+/e9/FzjHggULdPnyZQ0ePFhubm6qWrXqdX9Rz83NVdeuXXXfffdp6tSpSkhI0Pjx43X16lVNmjTppvX+WWFq+7MDBw6obdu28vLy0pgxY+Ti4qIPPvhAHTp00KZNm9SqVSu78cOGDVOVKlU0fvx4paSk6N1331VsbKyWLFly020Vdj+HDBmi+Ph4DRgwQMOHD9eJEyf0/vvv69tvv9WWLVvk4uKif//735o3b5527NihDz/8UJJsr/2BAwdq4cKFeuSRR/Tiiy9q+/btmjJlig4dOqTly5fb1XT48GE98cQTGjJkiAYNGqQGDRro999/V/v27fXLL79oyJAhqlmzprZu3aq4uDidOnVK77777k339VbmTUxM1BNPPKFOnTrpH//4hyTp0KFD2rJli+0PJoV9v+aZMmWKKlasqJdffllHjx7VzJkz5eLiIicnJ/3222+aMGGCtm3bpvj4eNWuXVuvvfaa3eM3bdqkJUuWaPjw4XJzc9Ps2bPVtWtX7dixQ02aNLnp83GtN998U05OTnrppZeUmZmpqVOnqm/fvtq+fbttzJw5cxQbG6u2bdtq5MiRSklJUc+ePVWlShXVqFGjyNsEUEoYAFDGZGZmGpKMHj16FPoxISEhRv/+/W33L1++bOTm5tqNOXHihOHm5mZMmjTJ1tajRw+jcePGN5zb29vbiImJuW6/1Wo16tWrZ0RFRRlWq9XW/vvvvxu1a9c2unTpUui5rqdnz56Gu7u78eOPP9raDh48aDg7OxvXftRf+1w0b97c6Nat2w3nj4mJyTePYfzxnEkyvLy8jNOnTxfYt2DBAltb//79DUnGsGHDbG1Wq9Xo1q2b4erqapw5c8YwDMPYsGGDIcnYsGHDTee8Xm2GYRiSjPHjx9vu9+zZ03B1dTWOHTtmazt58qTh6elptGvXzta2YMECQ5LRuXNnu5/ZyJEjDWdnZyMjI6PA7RV1P7/++mtDkrFo0SK7xyckJORr79+/v+Hh4WE3Ljk52ZBkDBw40K79pZdeMiQZ69evt7WFhIQYkoyEhAS7sZMnTzY8PDyMH374wa795ZdfNpydnY3U1NQb7uutzvvCCy8YXl5extWrV6+7jcK+X/NeN02aNDFycnJs7U888YRhsViM6OhouzkiIiKMkJAQuzZJhiRj165dtrYff/zRcHd3N/7617/a2vJeIydOnLC1tW/f3mjfvn2+esLCwozs7Gxb+3vvvWdIMvbt22cYhmFkZ2cb1apVM+69917jypUrtnHx8fGGJLs5AZQtnEYIoMzJysqSJHl6ehZ7Djc3N9siEbm5uTp79qwqV66sBg0a2J2y5+Pjo59//lk7d+687lw+Pj7avn27Tp48WWB/cnKyjhw5oieffFJnz57Vr7/+ql9//VUXL15Up06dtHnzZttRoJvNVZDc3FytXr1aPXv2VM2aNW3tYWFhioqKuunjfXx8dODAAR05cqTQ27xW79695evrW+jxsbGxtn/nnbaVk5OjtWvXFruGm8nNzdWaNWvUs2dPhYaG2toDAwP15JNP6ptvvrG9tvIMHjzY7rTEtm3bKjc3Vz/++GOhtnmz/Vy6dKm8vb3VpUsX2+vi119/VXh4uCpXrqwNGzbccP4vv/xSkjRq1Ci79hdffFGS8l23WLt27XyviaVLl6pt27aqUqWKXQ2dO3dWbm5uoU6fu5V5fXx8dPHiRdtpqwUp7Ps1T79+/ewWZmnVqpUMw9AzzzxjN65Vq1b66aefdPXqVbv2iIgIhYeH2+7XrFlTPXr00OrVq5Wbm3vT5+NaAwYMsLueq23btpL+OGInSbt27dLZs2c1aNAguwVd+vbtqypVqhR5ewBKD8IWgDLHy8tL0h/XNxWX1WrV9OnTVa9ePbm5ual69ery9fXV3r17lZmZaRs3duxYVa5cWS1btlS9evUUExOT7zqrqVOnav/+/QoODlbLli01YcIE2y9Rkmwhpn///vL19bW7ffjhh8rOzrZt82ZzFeTMmTO6dOmS6tWrl6+vQYMGN30uJk2apIyMDNWvX19NmzbV6NGjtXfv3ps+7s9q165d6LFOTk52YUeS6tevL0l231lU0s6cOaPff/+9wOckLCxMVqtVP/30k137n8OrJNsvvn++nup6CrOfR44cUWZmpvz8/PK9Ni5cuKDTp0/fcBs//vijnJycVLduXbv2gIAA+fj45AuFBf2cjhw5ooSEhHzb79y5syTdtIZbnXfo0KGqX7++oqOjVaNGDT3zzDNKSEiwm6uw79c81/7cvL29JUnBwcH52q1Wa745Cnov1a9fX7///nuRrtm7Xj3Xvo7yfk7X/hwrVKigWrVqFXl7AEoPrtkCUOZ4eXkpKChI+/fvL/Ycb7zxhl599VU988wzmjx5sqpWrSonJyeNGDHC7lqjsLAwHT58WCtXrlRCQoL++9//avbs2Xrttdc0ceJESVKfPn3Utm1bLV++XGvWrNG0adP0j3/8Q59++qmio6Nt802bNu26X0Sb9wW4N5vLDO3atdOxY8f0+eefa82aNfrwww81ffp0zZ07VwMHDizUHCW98ty1X8ScpzhHFW6Fs7Nzge3GNYtcFJfVapWfn58WLVpUYH9hjxZe7/m6VkE/J6vVqi5dumjMmDEFPiYvIJo1r5+fn5KTk7V69Wp99dVX+uqrr7RgwQL169dPCxculFT492ue6/3czP55Xo+jtgvA8QhbAMqkhx56SPPmzVNSUpIiIiKK/Phly5apY8eOmj9/vl17RkaGqlevbtfm4eGhxx57TI899phycnLUq1cvvf7664qLi7MtLR4YGKihQ4dq6NChOn36tO655x69/vrrio6OVp06dST9ERLz/qp/IzeaqyC+vr6qWLFigacBHj58uFDPR9WqVTVgwAANGDBAFy5cULt27TRhwgRb2CrsL/OFYbVadfz4cbtf4n/44QdJsv0VP+8v/xkZGXaPLej0vcLW5uvrq0qVKhX4nHz//fdycnLKd+TjVhRmP+vUqaO1a9eqTZs2xQqsISEhslqtOnLkiMLCwmzt6enpysjIUEhIyE3nqFOnji5cuFCo12ZRFGVeV1dXde/eXd27d5fVatXQoUP1wQcf6NVXX1XdunWL9H4tCQW9l3744QdVqlSpSKfLFlbez+no0aPq2LGjrf3q1atKSUlRs2bNSnybAG4PTiMEUCaNGTNGHh4eGjhwoNLT0/P1Hzt2zG7p6Gs5Ozvn+6vy0qVL9csvv9i1nT171u6+q6urGjVqJMMwdOXKFeXm5uY7BcnPz09BQUG2JaXDw8NVp04dvfXWW7pw4UK+WvJOSyrMXNfbl6ioKH322WdKTU21tR86dEirV6++7uOut4+VK1dW3bp17bbp4eEhKX/4Ka7333/f9m/DMPT+++/LxcVFnTp1kvTHL5/Ozs75rheaPXt2vrkKW5uzs7MiIyP1+eef252umJ6ersWLF+v++++3naJaUm62n3369FFubq4mT56c77FXr1696T49+OCDkpRvxcB33nlHktStW7eb1tinTx8lJSUV+FrJyMjIdz1TYRV23mtff05OTrZwkfcaLOz7taQkJSXZXQv2008/6fPPP1dkZOR1j1LdihYtWqhatWr65z//afd8L1q0qFCnrAIovTiyBaBMqlOnjhYvXqzHHntMYWFh6tevn5o0aaKcnBxt3bpVS5cutfsuqWs99NBDmjRpkgYMGKDWrVtr3759WrRoUb5rbCIjIxUQEKA2bdrI399fhw4d0vvvv69u3brJ09NTGRkZqlGjhh555BE1b95clStX1tq1a7Vz5069/fbbkv745fHDDz9UdHS0GjdurAEDBugvf/mLfvnlF23YsEFeXl764osvdP78+ZvOdT0TJ05UQkKC2rZtq6FDh+rq1au27we72fVXjRo1UocOHRQeHq6qVatq165dtuXn8+QtFjB8+HBFRUXJ2dlZjz/++A3nvR53d3clJCSof//+atWqlb766iutWrVKr7zyiu2ogbe3tx599FHNnDlTFotFderU0cqVKwu8fqgotf39739XYmKi7r//fg0dOlQVKlTQBx98oOzsbE2dOrVY+3Mr+9m+fXsNGTJEU6ZMUXJysiIjI+Xi4qIjR45o6dKleu+99/TII49cdxvNmzdX//79NW/ePGVkZKh9+/basWOHFi5cqJ49e9odJbme0aNHa8WKFXrooYf09NNPKzw8XBcvXtS+ffu0bNkypaSkFOvoUWHnHThwoM6dO6cHHnhANWrU0I8//qiZM2fqrrvush2tK+z7taQ0adJEUVFRdku/S7KdOlzSXF1dNWHCBA0bNkwPPPCA+vTpo5SUFMXHx6tOnTolemQZwG3msHUQAaAE/PDDD8agQYOMWrVqGa6uroanp6fRpk0bY+bMmcbly5dt4wpa+v3FF180AgMDjYoVKxpt2rQxkpKS8i3d/MEHHxjt2rUzqlWrZri5uRl16tQxRo8ebWRmZhqG8ceSzaNHjzaaN29ueHp6Gh4eHkbz5s2N2bNn56v122+/NXr16mWbKyQkxOjTp4+xbt26Is9VkE2bNhnh4eGGq6urERoaasydO9cYP378TZd+//vf/260bNnS8PHxMSpWrGg0bNjQeP311+2Wzr569aoxbNgww9fX17BYLLY585ZinzZtWr56rrf0u4eHh3Hs2DEjMjLSqFSpkuHv72+MHz8+39LeZ86cMXr37m1UqlTJqFKlijFkyBBj//79+ea8Xm2GkX/pd8MwjD179hhRUVFG5cqVjUqVKhkdO3Y0tm7dajcmb1nvnTt32rVfb0n6axVlPw3DMObNm2eEh4cbFStWNDw9PY2mTZsaY8aMMU6ePJlvzmtduXLFmDhxolG7dm3DxcXFCA4ONuLi4uxe/4bxx8/9ekv8nz9/3oiLizPq1q1ruLq6GtWrVzdat25tvPXWW3avg4Lc6rzLli0zIiMjDT8/P8PV1dWoWbOmMWTIEOPUqVO2eQr7fs37+SxdutSujuv9PPPeH3lL8RvGH6+ZmJgY4z//+Y9Rr149w83Nzbj77rvz/cyLsvT7tfUU9N4wDMOYMWOGERISYri5uRktW7Y0tmzZYoSHhxtdu3Yt8PkFUPpZDIOrMwEAAKQ/rgGMiYmxOwXUUaxWq3x9fdWrVy/985//dHQ5AIqBa7YAAAAc7PLly/muS/vXv/6lc+fOqUOHDo4pCsAt45otAAAAB9u2bZtGjhypRx99VNWqVdOePXs0f/58NWnSRI8++qijywNQTIQtAAAAB6tVq5aCg4M1Y8YMnTt3TlWrVlW/fv305ptvytXV1dHlASgmrtkCAAAAABNwzRYAAAAAmICwBQAAAAAm4JqtQrBarTp58qQ8PT35YkEAAACgHDMMQ+fPn1dQUJCcnG587IqwVQgnT55UcHCwo8sAAAAAUEr89NNPqlGjxg3HELYKwdPTU9IfT6iXl5eDqwEAAADgKFlZWQoODrZlhBshbBVC3qmDXl5ehC0AAAAAhbq8iAUyAAAAAMAEhC0AAAAAMAFhCwAAAABMQNgCAAAAABMQtgAAAADABIQtAAAAADABYQvlxpQpU3TvvffK09NTfn5+6tmzpw4fPmzrT0lJkcViKfC2dOlS27jhw4crPDxcbm5uuuuuu/Jt5/Dhw+rYsaP8/f3l7u6u0NBQjRs3TleuXLkduwkAAIBSgu/ZQrmxadMmxcTE6N5779XVq1f1yiuvKDIyUgcPHpSHh4eCg4N16tQpu8fMmzdP06ZNU3R0tF37M888o+3bt2vv3r35tuPi4qJ+/frpnnvukY+Pj7777jsNGjRIVqtVb7zxhqn7CAAAgNKDsIVyIyEhwe5+fHy8/Pz8tHv3brVr107Ozs4KCAiwG7N8+XL16dNHlStXtrXNmDFDknTmzJkCw1ZoaKhCQ0Nt90NCQrRx40Z9/fXXJbk7AAAAKOU4jRDlVmZmpiSpatWqBfbv3r1bycnJevbZZ29pO0ePHlVCQoLat29/S/MAAACgbCFsoVyyWq0aMWKE2rRpoyZNmhQ4Zv78+QoLC1Pr1q2LtY3WrVvL3d1d9erVU9u2bTVp0qRbKRkAAABlDGEL5VJMTIz279+vjz/+uMD+S5cuafHixbd0VGvJkiXas2ePFi9erFWrVumtt94q9lwAAAAoe7hmC+VObGysVq5cqc2bN6tGjRoFjlm2bJl+//139evXr9jbCQ4OliQ1atRIubm5Gjx4sF588UU5OzsXe04AAACUHRzZQrlhGIZiY2O1fPlyrV+/XrVr177u2Pnz5+vhhx+Wr69viWzbarXqypUrslqtJTIfAAAASj+ObKHciImJ0eLFi/X555/L09NTaWlpkiRvb29VrFjRNu7o0aPavHmzvvzyywLnOXr0qC5cuKC0tDRdunRJycnJkv44guXq6qpFixbJxcVFTZs2lZubm3bt2qW4uDg99thjcnFxMX0/AQAAUDpYDMMwHF1EaZeVlSVvb29lZmbKy8vL0eWgmCwWS4HtCxYs0NNPP227/8orr+g///mPUlJS5OSU/+Bvhw4dtGnTpnztJ06cUK1atbRkyRJNnTpVP/zwgwzDUEhIiP72t79p5MiRcnd3L7H9AQAAwO1XlGxA2CoEwhYAAAAAqWjZgGu2AAAAAMAEhC0AAAAAMAELZKDQar28ytElwMFS3uzm6BIAAADKDI5sAQAAAIAJCFsAAAAAYALCFgAAAACYgLAFAAAAACYgbAEAAACACQhbAAAAAGACwhYAAAAAmICwBQAAAAAmIGwBAAAAgAkIWwAAAABgAsIWAAAAAJiAsAUAAAAAJiBsAQAAAIAJCFsAAAAAYALCFgAAAACYgLAFAAAAACYgbAEAAACACQhbAAAAAGACwhYAAAAAmICwBQAAAAAmIGwBAAAAgAkIWwAAAABgAsIWAAAAAJiAsAUAAAAAJiBsAQAAAIAJCFsAAAAAYALCFgAAAACYgLAFAAAAACYgbAEAAACACRwatqZMmaJ7771Xnp6e8vPzU8+ePXX48GG7MR06dJDFYrG7Pffcc3ZjUlNT1a1bN1WqVEl+fn4aPXq0rl69ajdm48aNuueee+Tm5qa6desqPj7e7N0DAAAAUI45NGxt2rRJMTEx2rZtmxITE3XlyhVFRkbq4sWLduMGDRqkU6dO2W5Tp0619eXm5qpbt27KycnR1q1btXDhQsXHx+u1116zjTlx4oS6deumjh07Kjk5WSNGjNDAgQO1evXq27avAAAAAMqXCo7ceEJCgt39+Ph4+fn5affu3WrXrp2tvVKlSgoICChwjjVr1ujgwYNau3at/P39ddddd2ny5MkaO3asJkyYIFdXV82dO1e1a9fW22+/LUkKCwvTN998o+nTpysqKsq8HQQAAABQbpWqa7YyMzMlSVWrVrVrX7RokapXr64mTZooLi5Ov//+u60vKSlJTZs2lb+/v60tKipKWVlZOnDggG1M586d7eaMiopSUlJSgXVkZ2crKyvL7gYAAAAAReHQI1t/ZrVaNWLECLVp00ZNmjSxtT/55JMKCQlRUFCQ9u7dq7Fjx+rw4cP69NNPJUlpaWl2QUuS7X5aWtoNx2RlZenSpUuqWLGiXd+UKVM0ceLEEt9HAAAAAOVHqQlbMTEx2r9/v7755hu79sGDB9v+3bRpUwUGBqpTp046duyY6tSpY0otcXFxGjVqlO1+VlaWgoODTdkWAAAAgDtTqTiNMDY2VitXrtSGDRtUo0aNG45t1aqVJOno0aOSpICAAKWnp9uNybufd53X9cZ4eXnlO6olSW5ubvLy8rK7AQAAAEBRODRsGYah2NhYLV++XOvXr1ft2rVv+pjk5GRJUmBgoCQpIiJC+/bt0+nTp21jEhMT5eXlpUaNGtnGrFu3zm6exMRERURElNCeAAAAAIA9h4atmJgY/ec//9HixYvl6emptLQ0paWl6dKlS5KkY8eOafLkydq9e7dSUlK0YsUK9evXT+3atVOzZs0kSZGRkWrUqJGeeuopfffdd1q9erXGjRunmJgYubm5SZKee+45HT9+XGPGjNH333+v2bNn65NPPtHIkSMdtu8AAAAA7mwODVtz5sxRZmamOnTooMDAQNttyZIlkiRXV1etXbtWkZGRatiwoV588UX17t1bX3zxhW0OZ2dnrVy5Us7OzoqIiNDf/vY39evXT5MmTbKNqV27tlatWqXExEQ1b95cb7/9tj788EOWfQcAAABgGothGIajiyjtsrKy5O3trczMzHJ9/Vatl1c5ugQ4WMqb3RxdAgAAgEMVJRuUigUyAAAAAOBOQ9gCAAAAABMQtgAAAADABIQtAAAAADABYQsAAAAATEDYAgAAAAATELYAAAAAwASELQAAAAAwAWELAAAAAExA2AIAAAAAExC2AAAAAMAEhC0AAAAAMAFhCwAAAABMQNgCAAAAABMQtgAAAADABIQtAAAAADABYQsAAAAATEDYAgAAAAATELYAAAAAwASELQAAAAAwAWELAAAAAExA2AIAAAAAExC2AAAAAMAEhC0AAAAAMAFhCwAAAABMQNgCAAAAABMQtgAAAADABIQtAAAAADABYQsAAAAATEDYAgAAAAATELYAAAAAwASELQAAAAAwAWELAAAAAExA2AIAAAAAExC2AAAAAMAEhC0AAAAAMAFhCwAAAABMQNgCAAAAABMQtgAAAADABIQtAAAAADABYQsAAAAATEDYAgAAAAATELYAAAAAwASELQAAAAAwAWELAAAAAExA2AIAAAAAExC2AAAAAMAEhC0AAAAAMAFhCwAAAABMQNgCAAAAABMQtgAAAADABIQtAAAAADABYQsAAAAATEDYAgAAAAATELYAAAAAwASELQAAAAAwAWELAAAAAExA2AIAAAAAExC2AAAAAMAEhC0AAAAAMAFhCwAAAABMQNgCAAAAABMQtgAAAADABIQtAEC5snnzZnXv3l1BQUGyWCz67LPP7PrT09P19NNPKygoSJUqVVLXrl115MgRuzHHjh3TX//6V/n6+srLy0t9+vRRenq63ZiHH35YNWvWlLu7uwIDA/XUU0/p5MmTZu8eAKAUIWwBAMqVixcvqnnz5po1a1a+PsMw1LNnTx0/flyff/65vv32W4WEhKhz5866ePGi7fGRkZGyWCxav369tmzZopycHHXv3l1Wq9U2V8eOHfXJJ5/o8OHD+u9//6tjx47pkUceuW37CQBwPIthGIajiyjtsrKy5O3trczMTHl5eTm6HIep9fIqR5cAB0t5s5ujSwBKlMVi0fLly9WzZ09J0g8//KAGDRpo//79aty4sSTJarUqICBAb7zxhgYOHKg1a9YoOjpav/32m+3/hMzMTFWpUkVr1qxR586dC9zWihUr1LNnT2VnZ8vFxeW27B8AoOQVJRtwZAsAgP+VnZ0tSXJ3d7e1OTk5yc3NTd98841tjMVikZubm22Mu7u7nJycbGOude7cOS1atEitW7cmaAFAOULYAgDgfzVs2FA1a9ZUXFycfvvtN+Xk5Ogf//iHfv75Z506dUqSdN9998nDw0Njx47V77//rosXL+qll15Sbm6ubUyesWPHysPDQ9WqVVNqaqo+//xzR+wWAMBBCFsAAPwvFxcXffrpp/rhhx9UtWpVVapUSRs2bFB0dLScnP74L9PX11dLly7VF198ocqVK8vb21sZGRm65557bGPyjB49Wt9++63WrFkjZ2dn9evXT5y9DwDlRwVHFwAAQGkSHh6u5ORkZWZmKicnR76+vmrVqpVatGhhGxMZGaljx47p119/VYUKFeTj46OAgACFhobazVW9enVVr15d9evXV1hYmIKDg7Vt2zZFRETc7t0CADiAQ49sTZkyRffee688PT3l5+ennj176vDhw3ZjLl++rJiYGFWrVk2VK1dW79698y2vm5qaqm7duqlSpUry8/PT6NGjdfXqVbsxGzdu1D333CM3NzfVrVtX8fHxZu8eAKAM8/b2lq+vr44cOaJdu3apR48e+cZUr15dPj4+Wr9+vU6fPq2HH374uvPlrVSYd10YAODO59CwtWnTJsXExGjbtm1KTEzUlStXFBkZaVteV5JGjhypL774QkuXLtWmTZt08uRJ9erVy9afm5urbt26KScnR1u3btXChQsVHx+v1157zTbmxIkT6tatmzp27Kjk5GSNGDFCAwcO1OrVq2/r/gIAHO/ChQtKTk5WcnKypD/+j0hOTlZqaqokaenSpdq4caNt+fcuXbqoZ8+eioyMtM2xYMECbdu2TceOHdN//vMfPfrooxo5cqQaNGggSdq+fbvef/99JScn68cff9T69ev1xBNPqE6dOhzVAoBypFQt/X7mzBn5+flp06ZNateunTIzM+Xr66vFixfbvpvk+++/V1hYmJKSknTffffpq6++0kMPPaSTJ0/K399fkjR37lyNHTtWZ86ckaurq8aOHatVq1Zp//79tm09/vjjysjIUEJCwk3rYun3P7D0O1j6HXeCjRs3qmPHjvna+/fvr/j4eM2YMUPTpk1Tenq6AgMD1a9fP7366qtydXW1jX355ZcVHx+vc+fOqVatWnruuec0cuRIWSwWSdK+ffv0wgsv6LvvvtPFixcVGBiorl27aty4cfrLX/5y2/YVAFDyipINStU1W5mZmZKkqlWrSpJ2796tK1eu2H1nSd5KUXlhKykpSU2bNrUFLUmKiorS888/rwMHDujuu+9WUlJSvu89iYqK0ogRIwqsIzs72+40j6ysrJLaRQCAg3Xo0OGGi1QMHz5cw4cPv+Ecb775pt58883r9jdt2lTr168vdo0AgDtDqVmN0Gq1asSIEWrTpo2aNGkiSUpLS5Orq6t8fHzsxvr7+ystLc025s9BK68/r+9GY7KysnTp0qV8tUyZMkXe3t62W3BwcInsIwAAAIDyo9Qc2YqJidH+/fuv+4WQt1NcXJxGjRplu5+VlUXgAgBxOjE4nRgAiqJUhK3Y2FitXLlSmzdvVo0aNWztAQEBysnJUUZGht3RrfT0dAUEBNjG7Nixw26+vNUK/zzm2hUM09PT5eXlpYoVK+arx83NTW5ubiWybwAAAADKJ4eeRmgYhmJjY7V8+XKtX79etWvXtusPDw+Xi4uL1q1bZ2s7fPiwUlNTbas5RUREaN++fTp9+rRtTGJiory8vNSoUSPbmD/PkTeGFaEAAAAAmMWhR7ZiYmK0ePFiff755/L09LRdY+Xt7a2KFSvK29tbzz77rEaNGqWqVavKy8tLw4YNU0REhO677z5Jf3yxZKNGjfTUU09p6tSpSktL07hx4xQTE2M7OvXcc8/p/fff15gxY/TMM89o/fr1+uSTT7RqFafDAAAAADCHQ49szZkzR5mZmerQoYMCAwNttyVLltjGTJ8+XQ899JB69+6tdu3aKSAgQJ9++qmt39nZWStXrpSzs7MiIiL0t7/9Tf369dOkSZNsY2rXrq1Vq1YpMTFRzZs319tvv60PP/xQUVFRt3V/AQAAAJQfpep7tkorvmfrD1wYDy6MB58D4HMAQHlXlGxQapZ+BwAAAIA7CWELAAAAAExA2AIAAAAAExC2AAAAAMAEhC0AAAAAMAFhCwAAAABMQNgCAAAAABMQtgAAAADABIQtAAAAADABYQsAAAAATEDYAgAAAAATELYAAAAAwASELQAAAAAwAWELAAAAAExA2AIAAAAAExC2AAAAAMAEhC0AAAAAMAFhCwAAAABMQNgCAAAAABMQtgAAAADABIQtAAAAADABYQsAAAAATEDYAgAAAAATELYAAAAAwASELQAAAAAwAWELAAAAAExA2AIAAAAAExC2AAAAAMAEhC0AAAAAMAFhCwAAAABMQNgCAAAAABMQtgAAAADABIQtAAAAADABYQsAAAAATEDYAgAAAAATELYAAAAAwASELQAAAAAwAWELAAAAAExA2AIAAAAAExC2AAAAAMAEhC0AAAAAMAFhCwAAAABMQNgCAAAAABMQtgAAAADABIQtAAAAADABYQsAAAAATEDYAgAAAAATELYAAAAAwASELQAAAAAwAWELAAAAAExA2AIAAAAAExC2AAAAAMAEhC0AAAAAMAFhCwAAAABMQNgCAAAAABMQtgAAAADABIQtAAAAADABYQsAAAAATEDYAgAAAAATELYAAAAAwASELQAAAAAwAWELAAAAAExA2AIAAAAAExC2AAAAAMAEhC0AAAAAMAFhCwAAAABMQNgCAAAAABMQtgAAAADABIQtAAAAADBBscJWaGiozp49m689IyNDoaGht1wUAAAAAJR1xQpbKSkpys3NzdeenZ2tX3755ZaLAgAAAICyrkhha8WKFVqxYoUkafXq1bb7K1as0PLlyzV58mTVqlWr0PNt3rxZ3bt3V1BQkCwWiz777DO7/qeffloWi8Xu1rVrV7sx586dU9++feXl5SUfHx89++yzunDhgt2YvXv3qm3btnJ3d1dwcLCmTp1alN0GAAAAgCKrUJTBPXv2lCRZLBb179/frs/FxUW1atXS22+/Xej5Ll68qObNm+uZZ55Rr169ChzTtWtXLViwwHbfzc3Nrr9v3746deqUEhMTdeXKFQ0YMECDBw/W4sWLJUlZWVmKjIxU586dNXfuXO3bt0/PPPOMfHx8NHjw4ELXCgAAAABFUaSwZbVaJUm1a9fWzp07Vb169VvaeHR0tKKjo284xs3NTQEBAQX2HTp0SAkJCdq5c6datGghSZo5c6YefPBBvfXWWwoKCtKiRYuUk5Ojjz76SK6urmrcuLGSk5P1zjvvXDdsZWdnKzs723Y/KyurmHsIAAAAoLwq1jVbJ06cuOWgVVgbN26Un5+fGjRooOeff95uYY6kpCT5+PjYgpYkde7cWU5OTtq+fbttTLt27eTq6mobExUVpcOHD+u3334rcJtTpkyRt7e37RYcHGzS3gEAAAC4UxXpyNafrVu3TuvWrdPp06dtR7zyfPTRR7dcmPTHKYS9evVS7dq1dezYMb3yyiuKjo5WUlKSnJ2dlZaWJj8/P7vHVKhQQVWrVlVaWpokKS0tTbVr17Yb4+/vb+urUqVKvu3GxcVp1KhRtvtZWVkELgAAAABFUqywNXHiRE2aNEktWrRQYGCgLBZLSdclSXr88cdt/27atKmaNWumOnXqaOPGjerUqZMp25T+OHXx2mvDAAAAAKAoihW25s6dq/j4eD311FMlXc8NhYaGqnr16jp69Kg6deqkgIAAnT592m7M1atXde7cOdt1XgEBAUpPT7cbk3f/eteCAQAAAMCtKtY1Wzk5OWrdunVJ13JTP//8s86ePavAwEBJUkREhDIyMrR7927bmPXr18tqtapVq1a2MZs3b9aVK1dsYxITE9WgQYMCTyEEAAAAgJJQrLA1cOBA29Lqt+LChQtKTk5WcnKypD8W3khOTlZqaqouXLig0aNHa9u2bUpJSdG6devUo0cP1a1bV1FRUZKksLAwde3aVYMGDdKOHTu0ZcsWxcbG6vHHH1dQUJAk6cknn5Srq6ueffZZHThwQEuWLNF7771nd00WAAAAAJS0Yp1GePnyZc2bN09r165Vs2bN5OLiYtf/zjvvFGqeXbt2qWPHjrb7eQGof//+mjNnjvbu3auFCxcqIyNDQUFBioyM1OTJk+2up1q0aJFiY2PVqVMnOTk5qXfv3poxY4at39vbW2vWrFFMTIzCw8NVvXp1vfbaa3zHFgAAAABTFSts7d27V3fddZckaf/+/XZ9RVkso0OHDjIM47r9q1evvukcVatWvelRtmbNmunrr78udF0AAAAAcKuKFbY2bNhQ0nUAAAAAwB2lWNdsAQAAAABurFhHtjp27HjD0wXXr19f7IIAAAAA4E5QrLCVd71WnitXrig5OVn79+9X//79S6IuAAAAACjTihW2pk+fXmD7hAkTdOHChVsqCAAAAADuBCV6zdbf/vY3ffTRRyU5JQAAAACUSSUatpKSkuTu7l6SUwIAAABAmVSs0wh79epld98wDJ06dUq7du3Sq6++WiKFAQAAAEBZVqyw5e3tbXffyclJDRo00KRJkxQZGVkihQEAAABAWVassLVgwYKSrgMAAAAA7ijFClt5du/erUOHDkmSGjdurLvvvrtEigIAAACAsq5YYev06dN6/PHHtXHjRvn4+EiSMjIy1LFjR3388cfy9fUtyRoBAAAAoMwp1mqEw4YN0/nz53XgwAGdO3dO586d0/79+5WVlaXhw4eXdI0AAAAAUOYU68hWQkKC1q5dq7CwMFtbo0aNNGvWLBbIAAAAAAAV88iW1WqVi4tLvnYXFxdZrdZbLgoAAAAAyrpiha0HHnhAL7zwgk6ePGlr++WXXzRy5Eh16tSpxIoDAAAAgLKqWGHr/fffV1ZWlmrVqqU6deqoTp06ql27trKysjRz5sySrhEAAAAAypxiXbMVHBysPXv2aO3atfr+++8lSWFhYercuXOJFgcAAAAAZVWRjmytX79ejRo1UlZWliwWi7p06aJhw4Zp2LBhuvfee9W4cWN9/fXXZtUKAAAAAGVGkcLWu+++q0GDBsnLyytfn7e3t4YMGaJ33nmnxIoDAAAAgLKqSGHru+++U9euXa/bHxkZqd27d99yUQAAAABQ1hUpbKWnpxe45HueChUq6MyZM7dcFAAAAACUdUUKW3/5y1+0f//+6/bv3btXgYGBt1wUAAAAAJR1RQpbDz74oF599VVdvnw5X9+lS5c0fvx4PfTQQyVWHAAAAACUVUVa+n3cuHH69NNPVb9+fcXGxqpBgwaSpO+//16zZs1Sbm6u/ud//seUQgEAAACgLClS2PL399fWrVv1/PPPKy4uToZhSJIsFouioqI0a9Ys+fv7m1IoAAAAAJQlRf5S45CQEH355Zf67bffdPToURmGoXr16qlKlSpm1AcAAAAAZVKRw1aeKlWq6N577y3JWgAAAADgjlGkBTIAAAAAAIVD2AIAAAAAExC2AAAAAMAEhC0AAAAAMAFhCwAAAABMQNgCAAAAABMQtgAAAADABIQtAAAAADABYQsAAAAATEDYAgAAAAATELYAAAAAwASELQAAAAAwAWELAAAAAExA2AIAAAAAExC2AAAAAMAEhC0AAAAAMAFhCwAAAABMQNgCAAAAABMQtgAAAADABIQtAAAAADABYQsAAAAATEDYAgAAAAATELYAAAAAwASELQAAAAAwAWELAAAAAExA2AIAAAAAExC2AAAAAMAEhC0AAAAAMAFhCwAAAABMQNgCAAAAABMQtgAAAADABIQtAAAAADABYQsAAAAATEDYAgAAAAATELYAAAAAwASELQAAAAAwAWELAAAAAExA2AIAAAAAExC2AAAAAMAEhC0AAAAAMAFhCwAAAABMQNgCAAAAABM4NGxt3rxZ3bt3V1BQkCwWiz777DO7fsMw9NprrykwMFAVK1ZU586ddeTIEbsx586dU9++feXl5SUfHx89++yzunDhgt2YvXv3qm3btnJ3d1dwcLCmTp1q9q4BAAAAKOccGrYuXryo5s2ba9asWQX2T506VTNmzNDcuXO1fft2eXh4KCoqSpcvX7aN6du3rw4cOKDExEStXLlSmzdv1uDBg239WVlZioyMVEhIiHbv3q1p06ZpwoQJmjdvnun7BwAAAKD8quDIjUdHRys6OrrAPsMw9O6772rcuHHq0aOHJOlf//qX/P399dlnn+nxxx/XoUOHlJCQoJ07d6pFixaSpJkzZ+rBBx/UW2+9paCgIC1atEg5OTn66KOP5OrqqsaNGys5OVnvvPOOXSgDAAAAgJJUaq/ZOnHihNLS0tS5c2dbm7e3t1q1aqWkpCRJUlJSknx8fGxBS5I6d+4sJycnbd++3TamXbt2cnV1tY2JiorS4cOH9dtvvxW47ezsbGVlZdndAAAAAKAoSm3YSktLkyT5+/vbtfv7+9v60tLS5OfnZ9dfoUIFVa1a1W5MQXP8eRvXmjJliry9vW234ODgW98hAAAAAOVKqQ1bjhQXF6fMzEzb7aeffnJ0SQAAAADKmFIbtgICAiRJ6enpdu3p6em2voCAAJ0+fdqu/+rVqzp37pzdmILm+PM2ruXm5iYvLy+7GwAAAAAURakNW7Vr11ZAQIDWrVtna8vKytL27dsVEREhSYqIiFBGRoZ2795tG7N+/XpZrVa1atXKNmbz5s26cuWKbUxiYqIaNGigKlWq3Ka9AQAAAFDeODRsXbhwQcnJyUpOTpb0x6IYycnJSk1NlcVi0YgRI/T3v/9dK1as0L59+9SvXz8FBQWpZ8+ekqSwsDB17dpVgwYN0o4dO7RlyxbFxsbq8ccfV1BQkCTpySeflKurq5599lkdOHBAS5Ys0XvvvadRo0Y5aK8BAAAAlAcOXfp9165d6tixo+1+XgDq37+/4uPjNWbMGF28eFGDBw9WRkaG7r//fiUkJMjd3d32mEWLFik2NladOnWSk5OTevfurRkzZtj6vb29tWbNGsXExCg8PFzVq1fXa6+9xrLvAAAAAExlMQzDcHQRpV1WVpa8vb2VmZlZrq/fqvXyKkeXAAdLebObo0uAg/E5AD4HAJR3RckGpfaaLQAAAAAoywhbAAAAAGACwhYAAAAAmICwBQAAAAAmIGwBAAAAgAkIWwAAAABgAsIWAAAAAJiAsAUAAAAAJiBsAQAAAIAJCFsAAAAAYALCFgAAAACYgLAFAAAAACYgbAEAAACACQhbAAAAAGACwhYAAAAAmICwBQAAAAAmIGwBAAAAgAkIWwAAAABgAsIWAAAAAJiAsAUAAAAAJiBsAQAAAIAJCFsAAAAAYALCFgAAAACYgLAFAAAAACYgbAEAAACACQhbAAAAAGACwhYAAAAAmICwBQAAAAAmIGwBAAAAgAkIWwAAAABgAsIWAAAAAJiAsAUAAAAAJiBsAQAAAIAJCFsAAAAAYALCFgAAAACYgLAFAAAAACYgbAEAAACACQhbAAAAAGACwhYAAAAAmICwBQAAAAAmIGwBAAAAgAkIWwAAAABgAsIWAAAAAJiAsAUAAAAAJiBsAQAAAIAJCFsAAAAAYALCFgAAAACYgLAFAAAAACYgbAEAAACACQhbAAAAAGACwhYAAAAAmICwBQAAAAAmIGwBAAAAgAkIWwAAAABgAsIWAAAAAJiAsAUAAAAAJiBsAQAAAIAJCFsAAAAAYALCFgAAAACYgLAFAAAAACYgbAEAAACACQhbAAAAAGACwhYAAAAAmICwBQAAAAAmIGwBAAAAgAkIWwAAAABgAsIWAAAAAJiAsAUAAAAAJiBsAQAAAIAJCFsAAAAAYIJSHbYmTJggi8Vid2vYsKGt//Lly4qJiVG1atVUuXJl9e7dW+np6XZzpKamqlu3bqpUqZL8/Pw0evRoXb169XbvCgAAAIBypoKjC7iZxo0ba+3atbb7FSr8X8kjR47UqlWrtHTpUnl7eys2Nla9evXSli1bJEm5ubnq1q2bAgICtHXrVp06dUr9+vWTi4uL3njjjdu+LwAAAADKj1IftipUqKCAgIB87ZmZmZo/f74WL16sBx54QJK0YMEChYWFadu2bbrvvvu0Zs0aHTx4UGvXrpW/v7/uuusuTZ48WWPHjtWECRPk6up6u3cHAAAAQDlRqk8jlKQjR44oKChIoaGh6tu3r1JTUyVJu3fv1pUrV9S5c2fb2IYNG6pmzZpKSkqSJCUlJalp06by9/e3jYmKilJWVpYOHDhw3W1mZ2crKyvL7gYAAAAARVGqw1arVq0UHx+vhIQEzZkzRydOnFDbtm11/vx5paWlydXVVT4+PnaP8ff3V1pamiQpLS3NLmjl9ef1Xc+UKVPk7e1tuwUHB5fsjgEAAAC445Xq0wijo6Nt/27WrJlatWqlkJAQffLJJ6pYsaJp242Li9OoUaNs97OysghcAAAAAIqkVB/ZupaPj4/q16+vo0ePKiAgQDk5OcrIyLAbk56ebrvGKyAgIN/qhHn3C7oOLI+bm5u8vLzsbgAAAABQFGUqbF24cEHHjh1TYGCgwsPD5eLionXr1tn6Dx8+rNTUVEVEREiSIiIitG/fPp0+fdo2JjExUV5eXmrUqNFtrx8AAABA+VGqTyN86aWX1L17d4WEhOjkyZMaP368nJ2d9cQTT8jb21vPPvusRo0apapVq8rLy0vDhg1TRESE7rvvPklSZGSkGjVqpKeeekpTp05VWlqaxo0bp5iYGLm5uTl47wAAAADcyUp12Pr555/1xBNP6OzZs/L19dX999+vbdu2ydfXV5I0ffp0OTk5qXfv3srOzlZUVJRmz55te7yzs7NWrlyp559/XhEREfLw8FD//v01adIkR+0SAAAAgHKiVIetjz/++Ib97u7umjVrlmbNmnXdMSEhIfryyy9LujQAAAAAuKEydc0WAAAAUNLmzJmjZs2a2RZGi4iI0FdffSVJSklJkcViKfC2dOlSu3ni4+PVrFkzubu7y8/PTzExMY7YHZQipfrIFgAAAGC2GjVq6M0331S9evVkGIYWLlyoHj166Ntvv1XDhg116tQpu/Hz5s3TtGnT7L6m6J133tHbb7+tadOmqVWrVrp48aJSUlJu856gtCFsAQAAoFzr3r273f3XX39dc+bM0bZt29S4ceN8Xxm0fPly9enTR5UrV5Yk/fbbbxo3bpy++OILderUyTauWbNm5hePUo3TCAEAAID/lZubq48//lgXL160fZ3Qn+3evVvJycl69tlnbW2JiYmyWq365ZdfFBYWpho1aqhPnz766aefbmfpKIUIWwAAACj39u3bp8qVK8vNzU3PPfecli9fXuD3ss6fP19hYWFq3bq1re348eOyWq1644039O6772rZsmU6d+6cunTpopycnNu5GyhlCFsAAAAo9xo0aKDk5GRt375dzz//vPr376+DBw/ajbl06ZIWL15sd1RLkqxWq65cuaIZM2YoKipK9913n/7f//t/OnLkiDZs2HA7dwOlDNdsAQAAoNxzdXVV3bp1JUnh4eHauXOn3nvvPX3wwQe2McuWLdPvv/+ufv362T02MDBQkuyOhPn6+qp69epKTU29DdWjtOLIFgAAAHANq9Wq7Oxsu7b58+fr4Ycflq+vr117mzZtJEmHDx+2tZ07d06//vqrQkJCzC8WpRZHtgAAAFCuxcXFKTo6WjVr1tT58+e1ePFibdy4UatXr7aNOXr0qDZv3qwvv/wy3+Pr16+vHj166IUXXtC8efPk5eWluLg4NWzYUB07drydu4JShrAFAACAcu306dPq16+fTp06JW9vbzVr1kyrV69Wly5dbGM++ugj1ahRQ5GRkQXO8a9//UsjR45Ut27d5OTkpPbt2yshIUEuLi63azdQClkMwzAcXURpl5WVJW9vb2VmZsrLy8vR5ThMrZdXOboEOFjKm90cXQIcjM8B8DkAoLwrSjbgmi0AAAAAMAFhCwAAAABMwDVbAAAAKBJOKQanFBcOR7YAAAAAwASELQAAAAAwAWELAAAAAExA2AIAAAAAExC2AAAAAMAEhC0AAAAAMAFhCwAAAABMQNgCAAAAABMQtgAAAADABIQtAAAAADABYQsAAAAATEDYAgAAAAATELYAAAAAwASELQAAAAAwAWELAAAAAExA2AIAAAAAExC2AAAAAMAEhC0AAAAAMAFhCwAAAABMQNgCAAAAABMQtgAAAADABIQtAAAAADABYQsAAAAATEDYAgAAAAATELYAAAAAwASELQAAAAAwAWELAAAAAExA2AIAAAAAExC2AAAAAMAEhC0AAAAAMAFhCwAAAABMQNgCAAAAABMQtgAAAADABIQtAAAAADABYQsAAAAATEDYAgAAAAATELYAAAAAwASELQAAAAAwAWELAAAAAExA2AIAAAAAExC2AAAAAMAEhC0AAAAAMAFhCwAAAABMQNgCAAAAABMQtgAAAADABIQtAAAAADABYQsAAAAATEDYAgAAAAATELYAAAAAwASELQAAAAAwAWELAAAAAExA2AIAAAAAExC2AAAAAMAEhC0AAAAAMAFhCwAAAABMQNgCAAAAABOUq7A1a9Ys1apVS+7u7mrVqpV27Njh6JIAAAAA3KHKTdhasmSJRo0apfHjx2vPnj1q3ry5oqKidPr0aUeXBgAAAOAOVG7C1jvvvKNBgwZpwIABatSokebOnatKlSrpo48+cnRpAAAAAO5AFRxdwO2Qk5Oj3bt3Ky4uztbm5OSkzp07KykpKd/47OxsZWdn2+5nZmZKkrKysswvthSzZv/u6BLgYOX9PQA+B8DnAP7AZwHK82dB3r4bhnHTseUibP3666/Kzc2Vv7+/Xbu/v7++//77fOOnTJmiiRMn5msPDg42rUagLPB+19EVAHA0PgcASHwWSNL58+fl7e19wzHlImwVVVxcnEaNGmW7b7Vade7cOVWrVk0Wi8WBlcGRsrKyFBwcrJ9++kleXl6OLgeAA/A5AIDPARiGofPnzysoKOimY8tF2KpevbqcnZ2Vnp5u156enq6AgIB8493c3OTm5mbX5uPjY2aJKEO8vLz4cAXKOT4HAPA5UL7d7IhWnnKxQIarq6vCw8O1bt06W5vVatW6desUERHhwMoAAAAA3KnKxZEtSRo1apT69++vFi1aqGXLlnr33Xd18eJFDRgwwNGlAQAAALgDlZuw9dhjj+nMmTN67bXXlJaWprvuuksJCQn5Fs0ArsfNzU3jx4/Pd4opgPKDzwEAfA6gKCxGYdYsBAAAAAAUSbm4ZgsAAAAAbjfCFgAAAACYgLAFAAAAACYgbAEAAACACQhbAAAAAGACwhYAAAAAmICwBRRCdna2srOzHV0GgNvs4MGDGjp0qO6++24FBgYqMDBQd999t4YOHaqDBw86ujwAtwGfA7gVfM8WcB2JiYmaPn26kpKSlJWVJUny8vJSRESERo0apc6dOzu4QgBm+uqrr9SzZ0/dc889ioqKkr+/vyQpPT1diYmJ2r17tz7//HNFRUU5uFIAZuFzALeKsAUUYOHChRo4cKAeeeSRfB+ua9as0bJlyzR//nw99dRTDq4UgFmaN2+uHj16aNKkSQX2T5gwQZ9++qn27t17mysDcLvwOYBbRdgCClC/fn298MILiomJKbB/9uzZmj59uo4cOXKbKwNwu1SsWFHJyclq0KBBgf2HDx/WXXfdpUuXLt3mygDcLnwO4FZxzRZQgNTU1BueJtipUyf9/PPPt7EiALdbrVq1tGrVquv2r1q1SiEhIbexIgC3G58DuFUVHF0AUBo1btxY8+fP19SpUwvs/+ijj9SoUaPbXBWA22nSpEl68skntXHjRnXu3NnudOJ169YpISFBixcvdnCVAMzE5wBuFacRAgXYuHGjHnroIYWGhhb44Xr8+HGtWrVK7dq1c3ClAMy0detWzZgxQ0lJSUpLS5MkBQQEKCIiQi+88IIiIiIcXCEAs/E5gFtB2AKuIyUlRXPmzNG2bdvyfbg+99xzqlWrlmMLBAAAQKlG2AIAAAAAE7BABgAAxfDKK6/omWeecXQZAByIzwHcDGELKIb+/fvrgQcecHQZABzo559/VkpKiqPLAOBAv/zyC58DuCFWIwSKISgoSE5O/K0CKM/+9a9/OboEAA62cOFCR5eAUo5rtgAAuI5ff/1VH330Ub5VyFq3bq2nn35avr6+Dq4QAFCa8ad5oBh++uknztEG7nA7d+5U/fr1NWPGDHl7e6tdu3Zq166dvL29NWPGDDVs2FC7du1ydJkATHbp0iV98803OnjwYL6+y5cvc5QbN8SRLaAYvvvuO91zzz3Kzc11dCkATHLfffepefPmmjt3riwWi12fYRh67rnntHfvXiUlJTmoQgBm++GHHxQZGanU1FRZLBbdf//9+vjjjxUYGCjpj+/fDAoK4vcBXBfXbAEFWLFixQ37jx8/fpsqAeAo3333neLj4/MFLUmyWCwaOXKk7r77bgdUBuB2GTt2rJo0aaJdu3YpIyNDI0aMUJs2bbRx40bVrFnT0eWhDCBsAQXo2bOnLBaLbnTgt6BfwADcOQICArRjxw41bNiwwP4dO3bI39//NlcF4HbaunWr1q5dq+rVq6t69er64osvNHToULVt21YbNmyQh4eHo0tEKUfYAgoQGBio2bNnq0ePHgX2JycnKzw8/DZXBeB2eumllzR48GDt3r1bnTp1sgWr9PR0rVu3Tv/85z/11ltvObhKAGa6dOmSKlT4v1+XLRaL5syZo9jYWLVv316LFy92YHUoCwhbQAHCw8O1e/fu64atmx31AlD2xcTEqHr16po+fbpmz55tuybD2dlZ4eHhio+PV58+fRxcJQAz5S2EExYWZtf+/vvvS5IefvhhR5SFMoQFMoACfP3117p48aK6du1aYP/Fixe1a9cutW/f/jZXBsARrly5ol9//VWSVL16dbm4uDi4IgC3w5QpU/T111/ryy+/LLB/6NChmjt3rqxW622uDGUFYQsAAAAATMD3bAEAAACACQhbAAAAAGACwhYAAAAAmICwBQAAAAAmIGwBAPAnFotFn332maPLAADcAQhbAIByJS0tTcOGDVNoaKjc3NwUHBys7t27a926dY4uDQBwh+FLjQEA5UZKSoratGkjHx8fTZs2TU2bNtWVK1e0evVqxcTE6Pvvv3d0iQCAOwhHtgAA5cbQoUNlsVi0Y8cO9e7dW/Xr11fjxo01atQobdu2rcDHjB07VvXr11elSpUUGhqqV199VVeuXLH1f/fdd+rYsaM8PT3l5eWl8PBw7dq1S5L0448/qnv37qpSpYo8PDzUuHHj6345KgDgzsORLQBAuXDu3DklJCTo9ddfl4eHR75+Hx+fAh/n6emp+Ph4BQUFad++fRo0aJA8PT01ZswYSVLfvn119913a86cOXJ2dlZycrJcXFwkSTExMcrJydHmzZvl4eGhgwcPqnLlyqbtIwCgdCFsAQDKhaNHj8owDDVs2LBIjxs3bpzt37Vq1dJLL72kjz/+2Ba2UlNTNXr0aNu89erVs41PTU1V79691bRpU0lSaGjore4GAKAM4TRCAEC5YBhGsR63ZMkStWnTRgEBAapcubLGjRun1NRUW/+oUaM0cOBAde7cWW+++aaOHTtm6xs+fLj+/ve/q02bNho/frz27t17y/sBACg7CFsAgHKhXr16slgsRVoEIykpSX379tWDDz6olStX6ttvv9X//M//KCcnxzZmwoQJOnDggLp166b169erUaNGWr58uSRp4MCBOn78uJ566int27dPLVq00MyZM0t83wAApZPFKO6f+gAAKGOio6O1b98+HT58ON91WxkZGfLx8ZHFYtHy5cvVs2dPvf3225o9e7bd0aqBAwdq2bJlysjIKHAbTzzxhC5evKgVK1bk64uLi9OqVas4wgUA5QRHtgAA5casWbOUm5urli1b6r///a+OHDmiQ4cOacaMGYqIiMg3vl69ekpNTdXHH3+sY8eOacaMGbajVpJ06dIlxcbGauPGjfrxxx+1ZcsW7dy5U2FhYZKkESNGaPXq1Tpx4oT27NmjDRs22PoAAHc+FsgAAJQboaGh2rNnj15//XW9+OKLOnXqlHx9fRUeHq45c+bkG//www9r5MiRio2NVXZ2trp166ZXX31VEyZMkCQ5Ozvr7Nmz6tevn9LT01W9enX16tVLEydOlCTl5uYqJiZGP//8s7y8vNS1a1dNnz79du4yAMCBOI0QAAAAAEzAaYQAAAAAYALCFgAAAACYgLAFAAAAACYgbAEAAACACQhbAAAAAGACwhYAAAAAmICwBQAAAAAmIGwBAAAAgAkIWwAAAABgAsIWAAAAAJiAsAUAAAAAJvj/QLasS4E0rsUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Total amount of training data is: {train_features.shape[0]} \")\n",
    "create_class_distribution_bar_chart(train_features, title='Classes distribution before resampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling class imbalance using oversampling minority classes, SMOTE, and undersampling to majority classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply oversampling to minority classes\n",
    "# oversampler = RandomOverSampler(sampling_strategy='minority')\n",
    "# X_train_oversampled, y_train_oversampled = oversampler.fit_resample(X_train_normalized, y_train_encoded)\n",
    "\n",
    "# Apply SMOTE for synthetic data generation\n",
    "# smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "# X_train_resampled, y_train_resampled = smote.fit_resample(X_train_oversampled, y_train_oversampled) # the result after this is already balanced, why do we undersample?????\n",
    "\n",
    "# Apply undersampling to majority classes\n",
    "# undersampler = RandomUnderSampler(sampling_strategy='majority')\n",
    "# X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(y_train_resampled)\n",
    "# y_train_resampled_df    = pd.Series(y_train_resampled)\n",
    "# X_train_resampled_full  =  pd.concat([X_train_resampled, y_train_resampled_df], axis=1)\n",
    "y_train_resampled_df    = pd.Series(y_train_tomek)\n",
    "X_train_resampled_full  =  pd.concat([X_train_normalized, y_train_resampled_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of training data is: 7585 \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Total amount of training data is: {X_train_resampled_full.shape[0]} \")\n",
    "create_class_distribution_bar_chart(X_train_resampled_full, title='Classes distribution after resampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIMENSIONALITY REDUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "X_train_lda = lda.fit_transform(X_train_normalized, y_train_tomek) \n",
    "X_val_lda = lda.fit_transform(X_val_normalized, y_val_encoded) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(models, param_grids, X_train, y_train, X_val, y_val, scoring_metric='accuracy', cv=10):\n",
    "    all_models = []\n",
    "    \n",
    "    for model, param_grid in zip(models, param_grids):\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, verbose=2, scoring=scoring_metric)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        best_params = grid_search.best_params_\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # Store the best model and its parameters\n",
    "        all_models.append({'model': best_model, 'params': best_params})\n",
    "    \n",
    "    # Evaluate the best models on a separate validation set\n",
    "    models_report = []\n",
    "    for model_info in all_models:\n",
    "        model = model_info['model']\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        balanced_accuracy = balanced_accuracy_score(y_val, y_pred)\n",
    "        weighted_f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "        report = dict()\n",
    "                \n",
    "        report['model'] = model\n",
    "        report['best_params'] = model_info['params']\n",
    "        report['accuracy'] = accuracy\n",
    "        report['balanced_accuracy'] = balanced_accuracy\n",
    "        report['weighted_f1'] = weighted_f1\n",
    "\n",
    "\n",
    "        conf_matrix = multilabel_confusion_matrix(y_val_encoded, y_pred)\n",
    "        classes = ['bcc', 'mel', 'scc']\n",
    "        for i, class_label in enumerate(classes):\n",
    "            tp = conf_matrix[i, 1, 1]\n",
    "            fp = conf_matrix[i, 0, 1]\n",
    "            fn = conf_matrix[i, 1, 0]\n",
    "            tn = conf_matrix[i, 0, 0]\n",
    "\n",
    "            specificity = tn / (tn + fp)\n",
    "            sensitivity = tp / (tp + fn)\n",
    "            precision = tp / (tp + fp)\n",
    "            f1 = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "\n",
    "            binary_true_labels = np.where(np.array(y_val) == i, 1, 0)\n",
    "            binary_predicted_labels = np.where(np.array(y_pred) == i, 1, 0)\n",
    "            fpr, tpr, _ = roc_curve(binary_true_labels, binary_predicted_labels)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "\n",
    "            report[f'{class_label}_specificity'] = specificity\n",
    "            report[f'{class_label}_sensitivity'] = sensitivity\n",
    "            report[f'{class_label}_precision']  = precision\n",
    "            report[f'{class_label}_f1'] = f1\n",
    "            report[f'{class_label}_roc_auc'] = roc_auc\n",
    "\n",
    "        models_report.append(report)\n",
    "        \n",
    "        models_report.sort(key=lambda x: x['accuracy'], reverse=True)\n",
    "    \n",
    "    # return best_model, best_score, best_params, all_models\n",
    "    return models_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   1.2s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   1.7s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   1.6s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   1.5s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   2.1s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   5.3s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   5.9s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   5.2s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   6.2s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   7.2s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   1.2s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   2.1s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   4.8s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   4.5s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   2.5s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   8.2s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   4.4s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   4.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   5.2s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   4.8s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   2.2s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   2.7s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   3.4s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   3.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   3.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   5.2s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   6.2s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   4.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   5.1s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   2.7s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   2.1s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   1.7s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   1.5s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   4.7s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   2.1s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   5.2s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   5.5s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   6.3s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   6.9s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   7.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   3.4s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   2.1s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   3.9s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   1.7s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   4.5s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   5.8s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   9.1s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   3.2s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   3.5s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   8.4s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   1.7s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   3.9s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   2.1s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   2.8s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   3.3s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   8.5s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   2.9s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   6.5s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   4.5s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   4.9s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   5.2s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   3.7s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   6.8s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   4.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   6.1s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   4.1s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   4.1s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   7.8s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   5.6s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   6.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   4.4s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   4.6s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   3.8s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   6.1s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   7.5s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   7.9s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   4.7s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   5.6s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   4.8s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   6.2s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   4.1s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   4.2s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   4.3s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   4.1s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   5.3s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   5.6s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   5.7s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   4.4s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   5.7s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   5.9s\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.5s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.6s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.8s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   0.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.6s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   2.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   3.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   2.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   5.1s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   4.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   5.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   4.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   5.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   5.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   3.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   5.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   6.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   5.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   5.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   3.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   7.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   6.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   5.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   5.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   3.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   6.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   9.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   5.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   3.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   6.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   6.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   4.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   3.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   4.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   5.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   8.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   5.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   8.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   7.4s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   5.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   2.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   2.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   5.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   6.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   5.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   6.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   2.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   3.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   5.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   5.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   6.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   8.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   7.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.4s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.4s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   7.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   5.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   6.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   5.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   2.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   4.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   5.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   6.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   5.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   9.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   2.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   4.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   6.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   5.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   5.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   5.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   5.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   2.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   3.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   4.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   4.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   3.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   3.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  10.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   7.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   2.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   3.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   4.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   5.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   5.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   7.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   2.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   3.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   3.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   4.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   5.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   7.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   7.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   5.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   6.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   3.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   2.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   4.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   3.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   7.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   3.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   3.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   3.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   4.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   7.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   6.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   9.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   5.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   6.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   2.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   2.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   3.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   3.4s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   4.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   6.4s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   6.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   7.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   6.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   5.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   2.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   2.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   2.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   4.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   7.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   6.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   8.4s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   7.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   3.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   2.4s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   4.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   4.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   5.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   5.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   6.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   6.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   5.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   3.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   2.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   2.4s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.4s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   2.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   3.4s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   4.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   4.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   9.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   8.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   7.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   4.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   7.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   2.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   3.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   3.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   4.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   6.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   5.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   7.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   8.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   5.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   2.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   3.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   4.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   8.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   5.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   9.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   5.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   5.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   3.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   1.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   2.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   4.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   4.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   3.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   5.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   8.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   7.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   7.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   6.9s\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END .........................shrinkage=None, solver=svd; total time=   0.0s\n",
      "[CV] END .........................shrinkage=None, solver=svd; total time=   0.0s\n",
      "[CV] END .........................shrinkage=None, solver=svd; total time=   0.0s\n",
      "[CV] END .........................shrinkage=None, solver=svd; total time=   0.0s\n",
      "[CV] END .........................shrinkage=None, solver=svd; total time=   0.0s\n",
      "[CV] END .......................shrinkage=None, solver=eigen; total time=   0.0s\n",
      "[CV] END .......................shrinkage=None, solver=eigen; total time=   0.0s\n",
      "[CV] END .......................shrinkage=None, solver=eigen; total time=   0.0s\n",
      "[CV] END .......................shrinkage=None, solver=eigen; total time=   0.0s\n",
      "[CV] END .......................shrinkage=None, solver=eigen; total time=   0.0s\n",
      "[CV] END .........................shrinkage=auto, solver=svd; total time=   0.0s\n",
      "[CV] END .........................shrinkage=auto, solver=svd; total time=   0.0s\n",
      "[CV] END .........................shrinkage=auto, solver=svd; total time=   0.0s\n",
      "[CV] END .........................shrinkage=auto, solver=svd; total time=   0.0s\n",
      "[CV] END .........................shrinkage=auto, solver=svd; total time=   0.0s\n",
      "[CV] END .......................shrinkage=auto, solver=eigen; total time=   0.0s\n",
      "[CV] END .......................shrinkage=auto, solver=eigen; total time=   0.0s\n",
      "[CV] END .......................shrinkage=auto, solver=eigen; total time=   0.0s\n",
      "[CV] END .......................shrinkage=auto, solver=eigen; total time=   0.0s\n",
      "[CV] END .......................shrinkage=auto, solver=eigen; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=0.1, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=0.1, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=0.1, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=0.1, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=0.1, solver=svd; total time=   0.0s\n",
      "[CV] END ........................shrinkage=0.1, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=0.1, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=0.1, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=0.1, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=0.1, solver=eigen; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=0.5, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=0.5, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=0.5, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=0.5, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=0.5, solver=svd; total time=   0.0s\n",
      "[CV] END ........................shrinkage=0.5, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=0.5, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=0.5, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=0.5, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=0.5, solver=eigen; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=1.0, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=1.0, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=1.0, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=1.0, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=1.0, solver=svd; total time=   0.0s\n",
      "[CV] END ........................shrinkage=1.0, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=1.0, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=1.0, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=1.0, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=1.0, solver=eigen; total time=   0.0s\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "Model Report: [{'model': LogisticRegression(C=1, class_weight='balanced', multi_class='ovr',\n",
      "                   solver='liblinear'), 'best_params': {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}, 'accuracy': 0.6031496062992125, 'balanced_accuracy': 0.6303592579065399, 'weighted_f1': 0.6485785778017799, 'bcc_specificity': 0.844559585492228, 'bcc_sensitivity': 0.4859437751004016, 'bcc_precision': 0.6685082872928176, 'bcc_f1': 0.5627906976744186, 'bcc_roc_auc': 0.6652516802963149, 'mel_specificity': 0.8969594594594594, 'mel_sensitivity': 0.6710914454277286, 'mel_precision': 0.8817829457364341, 'mel_f1': 0.7621440536013401, 'mel_roc_auc': 0.784025452443594, 'scc_specificity': 0.7253401360544217, 'scc_sensitivity': 0.7340425531914894, 'scc_precision': 0.1760204081632653, 'scc_f1': 0.28395061728395066, 'scc_roc_auc': 0.7296913446229556}, {'model': SVC(C=10, class_weight='balanced', gamma=0.001, kernel='linear'), 'best_params': {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}, 'accuracy': 0.5826771653543307, 'balanced_accuracy': 0.6168657558748142, 'weighted_f1': 0.631404674940164, 'bcc_specificity': 0.8251295336787565, 'bcc_sensitivity': 0.4779116465863454, 'bcc_precision': 0.6380697050938338, 'bcc_f1': 0.5464982778415615, 'bcc_roc_auc': 0.6515205901325509, 'mel_specificity': 0.9087837837837838, 'mel_sensitivity': 0.6386430678466076, 'mel_precision': 0.8891170431211499, 'mel_f1': 0.7433476394849785, 'mel_roc_auc': 0.7737134258151956, 'scc_specificity': 0.7100340136054422, 'scc_sensitivity': 0.7340425531914894, 'scc_precision': 0.16829268292682928, 'scc_f1': 0.2738095238095238, 'scc_roc_auc': 0.7220382833984658}, {'model': LinearDiscriminantAnalysis(shrinkage=0.5, solver='eigen'), 'best_params': {'shrinkage': 0.5, 'solver': 'eigen'}, 'accuracy': 0.5803149606299213, 'balanced_accuracy': 0.6281417643208244, 'weighted_f1': 0.6333143554215817, 'bcc_specificity': 0.832901554404145, 'bcc_sensitivity': 0.4839357429718876, 'bcc_precision': 0.6513513513513514, 'bcc_f1': 0.555299539170507, 'bcc_roc_auc': 0.6584186486880164, 'mel_specificity': 0.9290540540540541, 'mel_sensitivity': 0.6238938053097345, 'mel_precision': 0.9096774193548387, 'mel_f1': 0.7401574803149606, 'mel_roc_auc': 0.7764739296818943, 'scc_specificity': 0.6921768707482994, 'scc_sensitivity': 0.776595744680851, 'scc_precision': 0.167816091954023, 'scc_f1': 0.27599243856332706, 'scc_roc_auc': 0.7343863077145752}, {'model': KNeighborsClassifier(algorithm='ball_tree', n_neighbors=7), 'best_params': {'algorithm': 'ball_tree', 'n_neighbors': 7, 'p': 2, 'weights': 'uniform'}, 'accuracy': 0.5464566929133858, 'balanced_accuracy': 0.5239977042419347, 'weighted_f1': 0.6001450032360883, 'bcc_specificity': 0.783678756476684, 'bcc_sensitivity': 0.4779116465863454, 'bcc_precision': 0.5876543209876544, 'bcc_f1': 0.5271317829457365, 'bcc_roc_auc': 0.6307952015315147, 'mel_specificity': 0.8885135135135135, 'mel_sensitivity': 0.6047197640117994, 'mel_precision': 0.8613445378151261, 'mel_f1': 0.7105719237435009, 'mel_roc_auc': 0.7466166387626564, 'scc_specificity': 0.7083333333333334, 'scc_sensitivity': 0.48936170212765956, 'scc_precision': 0.11825192802056556, 'scc_f1': 0.1904761904761905, 'scc_roc_auc': 0.5988475177304964}, {'model': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softprob', ...), 'best_params': {'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 200, 'subsample': 0.5}, 'accuracy': 0.5464566929133858, 'balanced_accuracy': 0.5715479756218119, 'weighted_f1': 0.6027804713528957, 'bcc_specificity': 0.8860103626943006, 'bcc_sensitivity': 0.35943775100401604, 'bcc_precision': 0.6704119850187266, 'bcc_f1': 0.46797385620915033, 'bcc_roc_auc': 0.6227240568491583, 'mel_specificity': 0.8902027027027027, 'mel_sensitivity': 0.6637168141592921, 'mel_precision': 0.8737864077669902, 'mel_f1': 0.7544006705783739, 'mel_roc_auc': 0.7769597584309973, 'scc_specificity': 0.6403061224489796, 'scc_sensitivity': 0.6914893617021277, 'scc_precision': 0.13319672131147542, 'scc_f1': 0.22336769759450173, 'scc_roc_auc': 0.6658977420755537}, {'model': RandomForestClassifier(max_depth=7, min_samples_leaf=2, min_samples_split=5,\n",
      "                       n_estimators=200), 'best_params': {'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, 'accuracy': 0.5456692913385827, 'balanced_accuracy': 0.5811082149472805, 'weighted_f1': 0.6059236573186405, 'bcc_specificity': 0.8911917098445595, 'bcc_sensitivity': 0.36947791164658633, 'bcc_precision': 0.6865671641791045, 'bcc_f1': 0.48041775456919067, 'bcc_roc_auc': 0.630334810745573, 'mel_specificity': 0.9054054054054054, 'mel_sensitivity': 0.6504424778761062, 'mel_precision': 0.8873239436619719, 'mel_f1': 0.7506382978723404, 'mel_roc_auc': 0.7779239416407557, 'scc_specificity': 0.6284013605442177, 'scc_sensitivity': 0.723404255319149, 'scc_precision': 0.13465346534653466, 'scc_f1': 0.2270450751252087, 'scc_roc_auc': 0.6759028079316833}]\n"
     ]
    }
   ],
   "source": [
    "# Define the list of models and their respective hyperparameter grids\n",
    "\n",
    "# Defining weights \n",
    "\n",
    "\n",
    "models = [\n",
    "    SVC(decision_function_shape='ovr', class_weight='balanced'),\n",
    "    LogisticRegression(multi_class = 'ovr', class_weight='balanced'),\n",
    "    KNeighborsClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    XGBClassifier()\n",
    "    ] \n",
    "        \n",
    "param_grids = [\n",
    "    {'kernel':('linear', 'rbf'), 'C':[0.1, 1, 10], 'gamma':[0.001, 0.01, 0.1]},\n",
    "    {'penalty' : ['l1', 'l2'], 'C':[0.1, 1, 10], 'solver': ['liblinear']},\n",
    "    {'n_neighbors': [3, 5, 7, 9], 'weights' : ['uniform', 'distance'], 'algorithm': ['ball_tree', 'kd_tree', 'brute'], 'p': [1, 2]}, \n",
    "    {'n_estimators' : [50, 100, 200], 'max_depth': [3, 5, 7, 9], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}, # still takes a lot of time\n",
    "    {'solver': ['svd', 'eigen'], 'shrinkage': [None, 'auto', 0.1, 0.5, 1.0]},\n",
    "    {'max_depth': [4, 5], 'learning_rate': [0.1, 0.01], 'n_estimators': [200, 300], 'subsample': [0.5, 0.7, 1.0], 'colsample_bytree': [0.8, 0.9, 1.0]}\n",
    "]\n",
    "\n",
    "# Call the function to compare models and get the best one\n",
    "# models_report = compare_models(models, param_grids, X_train_normalized, y_train_encoded, X_val_normalized, y_val_encoded, scoring_metric='f1_weighted', cv=5)\n",
    "\n",
    "# Training with the resampled training data X_train_resampled, y_train_resampled\n",
    "# models_report = compare_models(models, param_grids, X_train_resampled, y_train_resampled, X_val_normalized, y_val_encoded, scoring_metric='f1_weighted', cv=5)\n",
    "models_report = compare_models(models, param_grids, X_train_lda, y_train_tomek, X_val_lda, y_val_encoded, scoring_metric='balanced_accuracy', cv=5)\n",
    "\n",
    "# Save the best model to a file\n",
    "# best_model_filename = ROOT_PATH/'best_model.pkl'\n",
    "# with open(best_model_filename, 'wb') as file:\n",
    "#     pickle.dump(best_model, file)\n",
    "\n",
    "print(\"Model Report:\", models_report)\n",
    "# print(\"Best Score:\", best_score)\n",
    "# print(\"Best Params:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,)\n",
      "[{'model': LogisticRegression(C=1, class_weight='balanced', multi_class='ovr',\n",
      "                   solver='liblinear'), 'best_params': {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}, 'accuracy': 0.6031496062992125, 'balanced_accuracy': 0.6303592579065399, 'weighted_f1': 0.6485785778017799, 'bcc_specificity': 0.844559585492228, 'bcc_sensitivity': 0.4859437751004016, 'bcc_precision': 0.6685082872928176, 'bcc_f1': 0.5627906976744186, 'bcc_roc_auc': 0.6652516802963149, 'mel_specificity': 0.8969594594594594, 'mel_sensitivity': 0.6710914454277286, 'mel_precision': 0.8817829457364341, 'mel_f1': 0.7621440536013401, 'mel_roc_auc': 0.784025452443594, 'scc_specificity': 0.7253401360544217, 'scc_sensitivity': 0.7340425531914894, 'scc_precision': 0.1760204081632653, 'scc_f1': 0.28395061728395066, 'scc_roc_auc': 0.7296913446229556}, {'model': SVC(C=10, class_weight='balanced', gamma=0.001, kernel='linear'), 'best_params': {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}, 'accuracy': 0.5826771653543307, 'balanced_accuracy': 0.6168657558748142, 'weighted_f1': 0.631404674940164, 'bcc_specificity': 0.8251295336787565, 'bcc_sensitivity': 0.4779116465863454, 'bcc_precision': 0.6380697050938338, 'bcc_f1': 0.5464982778415615, 'bcc_roc_auc': 0.6515205901325509, 'mel_specificity': 0.9087837837837838, 'mel_sensitivity': 0.6386430678466076, 'mel_precision': 0.8891170431211499, 'mel_f1': 0.7433476394849785, 'mel_roc_auc': 0.7737134258151956, 'scc_specificity': 0.7100340136054422, 'scc_sensitivity': 0.7340425531914894, 'scc_precision': 0.16829268292682928, 'scc_f1': 0.2738095238095238, 'scc_roc_auc': 0.7220382833984658}, {'model': LinearDiscriminantAnalysis(shrinkage=0.5, solver='eigen'), 'best_params': {'shrinkage': 0.5, 'solver': 'eigen'}, 'accuracy': 0.5803149606299213, 'balanced_accuracy': 0.6281417643208244, 'weighted_f1': 0.6333143554215817, 'bcc_specificity': 0.832901554404145, 'bcc_sensitivity': 0.4839357429718876, 'bcc_precision': 0.6513513513513514, 'bcc_f1': 0.555299539170507, 'bcc_roc_auc': 0.6584186486880164, 'mel_specificity': 0.9290540540540541, 'mel_sensitivity': 0.6238938053097345, 'mel_precision': 0.9096774193548387, 'mel_f1': 0.7401574803149606, 'mel_roc_auc': 0.7764739296818943, 'scc_specificity': 0.6921768707482994, 'scc_sensitivity': 0.776595744680851, 'scc_precision': 0.167816091954023, 'scc_f1': 0.27599243856332706, 'scc_roc_auc': 0.7343863077145752}, {'model': KNeighborsClassifier(algorithm='ball_tree', n_neighbors=7), 'best_params': {'algorithm': 'ball_tree', 'n_neighbors': 7, 'p': 2, 'weights': 'uniform'}, 'accuracy': 0.5464566929133858, 'balanced_accuracy': 0.5239977042419347, 'weighted_f1': 0.6001450032360883, 'bcc_specificity': 0.783678756476684, 'bcc_sensitivity': 0.4779116465863454, 'bcc_precision': 0.5876543209876544, 'bcc_f1': 0.5271317829457365, 'bcc_roc_auc': 0.6307952015315147, 'mel_specificity': 0.8885135135135135, 'mel_sensitivity': 0.6047197640117994, 'mel_precision': 0.8613445378151261, 'mel_f1': 0.7105719237435009, 'mel_roc_auc': 0.7466166387626564, 'scc_specificity': 0.7083333333333334, 'scc_sensitivity': 0.48936170212765956, 'scc_precision': 0.11825192802056556, 'scc_f1': 0.1904761904761905, 'scc_roc_auc': 0.5988475177304964}, {'model': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softprob', ...), 'best_params': {'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 200, 'subsample': 0.5}, 'accuracy': 0.5464566929133858, 'balanced_accuracy': 0.5715479756218119, 'weighted_f1': 0.6027804713528957, 'bcc_specificity': 0.8860103626943006, 'bcc_sensitivity': 0.35943775100401604, 'bcc_precision': 0.6704119850187266, 'bcc_f1': 0.46797385620915033, 'bcc_roc_auc': 0.6227240568491583, 'mel_specificity': 0.8902027027027027, 'mel_sensitivity': 0.6637168141592921, 'mel_precision': 0.8737864077669902, 'mel_f1': 0.7544006705783739, 'mel_roc_auc': 0.7769597584309973, 'scc_specificity': 0.6403061224489796, 'scc_sensitivity': 0.6914893617021277, 'scc_precision': 0.13319672131147542, 'scc_f1': 0.22336769759450173, 'scc_roc_auc': 0.6658977420755537}, {'model': RandomForestClassifier(max_depth=7, min_samples_leaf=2, min_samples_split=5,\n",
      "                       n_estimators=200), 'best_params': {'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, 'accuracy': 0.5456692913385827, 'balanced_accuracy': 0.5811082149472805, 'weighted_f1': 0.6059236573186405, 'bcc_specificity': 0.8911917098445595, 'bcc_sensitivity': 0.36947791164658633, 'bcc_precision': 0.6865671641791045, 'bcc_f1': 0.48041775456919067, 'bcc_roc_auc': 0.630334810745573, 'mel_specificity': 0.9054054054054054, 'mel_sensitivity': 0.6504424778761062, 'mel_precision': 0.8873239436619719, 'mel_f1': 0.7506382978723404, 'mel_roc_auc': 0.7779239416407557, 'scc_specificity': 0.6284013605442177, 'scc_sensitivity': 0.723404255319149, 'scc_precision': 0.13465346534653466, 'scc_f1': 0.2270450751252087, 'scc_roc_auc': 0.6759028079316833}]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(models_report).shape)\n",
    "print(models_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   {   'accuracy': 0.8299212598425196,\n",
      "        'balanced_accuracy': 0.7092838812729106,\n",
      "        'bcc_f1': 0.8132530120481927,\n",
      "        'bcc_precision': 0.8132530120481928,\n",
      "        'bcc_roc_auc': 0.8463933454023347,\n",
      "        'bcc_sensitivity': 0.8132530120481928,\n",
      "        'bcc_specificity': 0.8795336787564767,\n",
      "        'best_params': {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'},\n",
      "        'mel_f1': 0.8739255014326647,\n",
      "        'mel_precision': 0.8495821727019499,\n",
      "        'mel_roc_auc': 0.8586362911584151,\n",
      "        'mel_sensitivity': 0.8997050147492626,\n",
      "        'mel_specificity': 0.8175675675675675,\n",
      "        'model': SVC(C=10, class_weight='balanced', gamma=0.1),\n",
      "        'scc_f1': 0.527027027027027,\n",
      "        'scc_precision': 0.7222222222222222,\n",
      "        'scc_roc_auc': 0.7010692574902301,\n",
      "        'scc_sensitivity': 0.4148936170212766,\n",
      "        'scc_specificity': 0.9872448979591837,\n",
      "        'weighted_f1': 0.8244582917416435},\n",
      "    {   'accuracy': 0.8031496062992126,\n",
      "        'balanced_accuracy': 0.656447669798002,\n",
      "        'bcc_f1': 0.7861271676300577,\n",
      "        'bcc_precision': 0.7555555555555555,\n",
      "        'bcc_roc_auc': 0.8241463262375929,\n",
      "        'bcc_sensitivity': 0.8192771084337349,\n",
      "        'bcc_specificity': 0.8290155440414507,\n",
      "        'best_params': {   'colsample_bytree': 0.9,\n",
      "                           'learning_rate': 0.1,\n",
      "                           'max_depth': 5,\n",
      "                           'n_estimators': 300,\n",
      "                           'subsample': 0.7},\n",
      "        'mel_f1': 0.8602941176470588,\n",
      "        'mel_precision': 0.8577712609970675,\n",
      "        'mel_roc_auc': 0.8494902535278641,\n",
      "        'mel_sensitivity': 0.8628318584070797,\n",
      "        'mel_specificity': 0.8361486486486487,\n",
      "        'model': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softprob', ...),\n",
      "        'scc_f1': 0.38028169014084506,\n",
      "        'scc_precision': 0.5625,\n",
      "        'scc_roc_auc': 0.6346884498480243,\n",
      "        'scc_sensitivity': 0.2872340425531915,\n",
      "        'scc_specificity': 0.9821428571428571,\n",
      "        'weighted_f1': 0.795682850486389},\n",
      "    {   'accuracy': 0.7370078740157481,\n",
      "        'balanced_accuracy': 0.693888338138848,\n",
      "        'bcc_f1': 0.7350427350427351,\n",
      "        'bcc_precision': 0.6972972972972973,\n",
      "        'bcc_roc_auc': 0.7797459267120295,\n",
      "        'bcc_sensitivity': 0.7771084337349398,\n",
      "        'bcc_specificity': 0.7823834196891192,\n",
      "        'best_params': {   'algorithm': 'ball_tree',\n",
      "                           'n_neighbors': 3,\n",
      "                           'p': 2,\n",
      "                           'weights': 'distance'},\n",
      "        'mel_f1': 0.7945425361155698,\n",
      "        'mel_precision': 0.8714788732394366,\n",
      "        'mel_roc_auc': 0.8033888423822051,\n",
      "        'mel_sensitivity': 0.7300884955752213,\n",
      "        'mel_specificity': 0.8766891891891891,\n",
      "        'model': KNeighborsClassifier(algorithm='ball_tree', n_neighbors=3, weights='distance'),\n",
      "        'scc_f1': 0.4481327800829876,\n",
      "        'scc_precision': 0.3673469387755102,\n",
      "        'scc_roc_auc': 0.7476932262266609,\n",
      "        'scc_sensitivity': 0.574468085106383,\n",
      "        'scc_specificity': 0.9209183673469388,\n",
      "        'weighted_f1': 0.7455713408389285},\n",
      "    {   'accuracy': 0.7370078740157481,\n",
      "        'balanced_accuracy': 0.6592230971207997,\n",
      "        'bcc_f1': 0.7243346007604562,\n",
      "        'bcc_precision': 0.6877256317689531,\n",
      "        'bcc_roc_auc': 0.7704834883575753,\n",
      "        'bcc_sensitivity': 0.7650602409638554,\n",
      "        'bcc_specificity': 0.7759067357512953,\n",
      "        'best_params': {   'max_depth': 9,\n",
      "                           'min_samples_leaf': 1,\n",
      "                           'min_samples_split': 2,\n",
      "                           'n_estimators': 200},\n",
      "        'mel_f1': 0.799375487900078,\n",
      "        'mel_precision': 0.8490878938640133,\n",
      "        'mel_roc_auc': 0.8007230128358447,\n",
      "        'mel_sensitivity': 0.7551622418879056,\n",
      "        'mel_specificity': 0.8462837837837838,\n",
      "        'model': RandomForestClassifier(max_depth=9, n_estimators=200),\n",
      "        'scc_f1': 0.4154589371980676,\n",
      "        'scc_precision': 0.3805309734513274,\n",
      "        'scc_roc_auc': 0.6989614994934144,\n",
      "        'scc_sensitivity': 0.4574468085106383,\n",
      "        'scc_specificity': 0.9404761904761905,\n",
      "        'weighted_f1': 0.7415341354894318},\n",
      "    {   'accuracy': 0.6937007874015748,\n",
      "        'balanced_accuracy': 0.6301509307171572,\n",
      "        'bcc_f1': 0.6831364124597206,\n",
      "        'bcc_precision': 0.7344110854503464,\n",
      "        'bcc_roc_auc': 0.7447952431487609,\n",
      "        'bcc_sensitivity': 0.6385542168674698,\n",
      "        'bcc_specificity': 0.8510362694300518,\n",
      "        'best_params': {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'},\n",
      "        'mel_f1': 0.8103448275862069,\n",
      "        'mel_precision': 0.8645484949832776,\n",
      "        'mel_roc_auc': 0.8128562744160089,\n",
      "        'mel_sensitivity': 0.7625368731563422,\n",
      "        'mel_specificity': 0.8631756756756757,\n",
      "        'model': LogisticRegression(C=1, class_weight='balanced', multi_class='ovr',\n",
      "                   solver='liblinear'),\n",
      "        'scc_f1': 0.27627627627627627,\n",
      "        'scc_precision': 0.19246861924686193,\n",
      "        'scc_roc_auc': 0.6626230279345781,\n",
      "        'scc_sensitivity': 0.48936170212765956,\n",
      "        'scc_specificity': 0.8358843537414966,\n",
      "        'weighted_f1': 0.7209336192742984},\n",
      "    {   'accuracy': 0.6771653543307087,\n",
      "        'balanced_accuracy': 0.6424850850083319,\n",
      "        'bcc_f1': 0.6746987951807231,\n",
      "        'bcc_precision': 0.7421686746987952,\n",
      "        'bcc_roc_auc': 0.7399364296564497,\n",
      "        'bcc_sensitivity': 0.6184738955823293,\n",
      "        'bcc_specificity': 0.8613989637305699,\n",
      "        'best_params': {'shrinkage': None, 'solver': 'svd'},\n",
      "        'mel_f1': 0.80517380759903,\n",
      "        'mel_precision': 0.8908765652951699,\n",
      "        'mel_roc_auc': 0.8157363668978713,\n",
      "        'mel_sensitivity': 0.7345132743362832,\n",
      "        'mel_specificity': 0.8969594594594594,\n",
      "        'model': LinearDiscriminantAnalysis(),\n",
      "        'scc_f1': 0.2769230769230769,\n",
      "        'scc_precision': 0.18243243243243243,\n",
      "        'scc_roc_auc': 0.6843428860906065,\n",
      "        'scc_sensitivity': 0.574468085106383,\n",
      "        'scc_specificity': 0.79421768707483,\n",
      "        'weighted_f1': 0.7149122919550486}]\n"
     ]
    }
   ],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(models_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model to a file\n",
    "# best_model_filename = r'../models/best_model_multiclassSVM.pkl'\n",
    "# with open(best_model_filename, 'wb') as file:\n",
    "#      pickle.dump(best_model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
