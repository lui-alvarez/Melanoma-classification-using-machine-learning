{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../helpers/')\n",
    "\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import natsort\n",
    "import cv2\n",
    "import csv\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# importing packages\n",
    "from preprocessing import Preprocessing\n",
    "from feature_extraction import FeatureExtraction\n",
    "\n",
    "preprocessor = Preprocessing()\n",
    "feature_extractor = FeatureExtraction()\n",
    "\n",
    "# To allow auto reload to this notebook after modifying any external file imported\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = Path(Path(os.getcwd())/\"../challenge2\")\n",
    "TRAIN_PATH = ROOT_PATH/\"train\"\n",
    "VAL_PATH = ROOT_PATH/\"val\"\n",
    "\n",
    "train_bcc = sorted(glob(str(TRAIN_PATH/'bcc/*')))\n",
    "train_mel = sorted(glob(str(TRAIN_PATH/'mel/*')))\n",
    "train_scc = sorted(glob(str(TRAIN_PATH/'scc/*')))\n",
    "\n",
    "val_bcc = sorted(glob(str(VAL_PATH/'bcc/*')))\n",
    "val_mel = sorted(glob(str(VAL_PATH/'mel/*')))\n",
    "val_scc = sorted(glob(str(VAL_PATH/'scc/*')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVING PICKLES OF PREPROCESSED IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing and feature extraction\n",
    "prep_imgs_dir = r'../output/'\n",
    "\n",
    "bcc_train_prep_filename    = 'bcc_train_prep_images.pkl'\n",
    "bcc_val_prep_filename      = 'bcc_val_prep_images.pkl'\n",
    "\n",
    "mel_train_prep_filename   = 'mel_train_prep_images.pkl'\n",
    "mel_val_prep_filename     = 'mel_val_prep_images.pkl'\n",
    "\n",
    "scc_train_prep_filename   = 'scc_train_prep_images.pkl'\n",
    "scc_val_prep_filename     = 'scc_val_prep_images.pkl'\n",
    "\n",
    "\n",
    "filenames_prep_list = [bcc_train_prep_filename, bcc_val_prep_filename, mel_train_prep_filename,  mel_val_prep_filename, scc_train_prep_filename, scc_val_prep_filename]\n",
    "dir_list = [train_bcc, val_bcc, train_mel, val_mel, train_scc, val_scc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1993it [13:20,  2.49it/s]\n",
      "170it [00:59, 10.06it/s]c:\\master\\udg\\CAD\\project\\notebooks\\../helpers\\preprocessing.py:128: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  if mean_outside / mean_inside < threshold:\n",
      "498it [02:54,  2.85it/s]\n",
      "376it [02:09,  2.89it/s]\n",
      "94it [00:36,  2.59it/s]\n"
     ]
    }
   ],
   "source": [
    "subsample               = False\n",
    "\n",
    "for index, filename in enumerate(filenames_prep_list):\n",
    "\n",
    "    preprocessed_images = []\n",
    "\n",
    "    for count, image_path in tqdm(enumerate(dir_list[index])):\n",
    "\n",
    "        if subsample:\n",
    "            if count == 999: # only 1k per class\n",
    "                break\n",
    "\n",
    "        # reading the image \n",
    "        image = cv2.imread(image_path,cv2.IMREAD_COLOR)\n",
    "\n",
    "        # 1. Copping black frame\n",
    "        image_without_black_frame, _ = preprocessor.crop_frame(image)\n",
    "\n",
    "        # 2. Resizing\n",
    "        image_resized = preprocessor.resize_images(image_without_black_frame, preserve_ratio=True)\n",
    "\n",
    "        # 3. Removing hair\n",
    "        image_without_hair = preprocessor.extract_hair(image_resized)\n",
    "\n",
    "        # Saving the preprocessed image to a list\n",
    "        preprocessed_images.append(image_without_hair)\n",
    "\n",
    "    # Saving the preprocessed images to a file\n",
    "    with open(prep_imgs_dir+filename, 'wb') as file:\n",
    "        pickle.dump(preprocessed_images, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRACTING FEATURES FROM PREPROCESSED IMAGES SAVED IN PICKLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING PICKLES \n",
    "\n",
    "with open(os.path.join(prep_imgs_dir, mel_train_prep_filename), 'rb') as file:\n",
    "    mel_train_prep_images = pickle.load(file)\n",
    "with open(os.path.join(prep_imgs_dir, mel_val_prep_filename), 'rb') as file:\n",
    "    mel_val_prep_images = pickle.load(file)\n",
    "\n",
    "with open(os.path.join(prep_imgs_dir, bcc_train_prep_filename), 'rb') as file:\n",
    "    bcc_train_prep_images = pickle.load(file)\n",
    "with open(os.path.join(prep_imgs_dir, bcc_val_prep_filename), 'rb') as file:\n",
    "    bcc_val_prep_images = pickle.load(file)\n",
    "\n",
    "with open(os.path.join(prep_imgs_dir, scc_train_prep_filename), 'rb') as file:\n",
    "    scc_train_prep_images = pickle.load(file)\n",
    "with open(os.path.join(prep_imgs_dir, scc_val_prep_filename), 'rb') as file:\n",
    "    scc_val_prep_images = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "376it [09:59,  1.59s/it]\n",
      "94it [02:15,  1.44s/it]\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing and feature extraction\n",
    "features_dir = r'../output/features/'\n",
    "\n",
    "experiment              = 0\n",
    "subsample               = False\n",
    "\n",
    "bcc_train_filename    = f'{experiment}_bcc_train_features.csv'\n",
    "bcc_val_filename      = f'{experiment}_bcc_val_features.csv'\n",
    "\n",
    "mel_train_filename    = f'{experiment}_mel_train_features.csv'\n",
    "mel_val_filename      = f'{experiment}_mel_val_features.csv'\n",
    "\n",
    "scc_train_filename   = f'{experiment}_scc_train_features.csv'\n",
    "scc_val_filename     = f'{experiment}_scc_val_features.csv'\n",
    "\n",
    "filenames_list = [bcc_train_filename, bcc_val_filename, mel_train_filename, mel_val_filename, scc_train_filename, scc_val_filename]\n",
    "images_lists = [bcc_train_prep_images, bcc_val_prep_images, mel_train_prep_images, mel_val_prep_images, scc_train_prep_images, scc_val_prep_images]\n",
    "\n",
    "labels = [0, 0, 1, 1, 2, 2] # bcc = 0, mel = 1, scc = 2\n",
    "\n",
    "\n",
    "# Loop through the lists of images and their corresponding filenames\n",
    "for filename, image_list, label in zip(filenames_list, images_lists, labels):\n",
    "    with open(os.path.join(features_dir, filename), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        for count, preprocessed_image in tqdm(enumerate(image_list)):\n",
    "            if subsample and count == 999:  # Only 1k per class\n",
    "                break\n",
    "\n",
    "            # 5. Extracting features\n",
    "            feature_vector = feature_extractor.fit(preprocessed_image)\n",
    "\n",
    "            # 6. Add label column\n",
    "            feature_vector = np.append(feature_vector, label)\n",
    "\n",
    "            # Write the feature vector to the CSV file\n",
    "            writer.writerow(feature_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPARING THE DATA FOR MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, f1_score, multilabel_confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "from feature_selection import FeatureSelection\n",
    "\n",
    "select_feature = FeatureSelection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dir = r'../output/features/'\n",
    "experiment              = 0\n",
    "\n",
    "train_bcc_df = pd.read_csv(os.path.join(features_dir,f'{experiment}_bcc_train_features.csv'),  header = None)\n",
    "val_bcc_df = pd.read_csv(os.path.join(features_dir, f'{experiment}_bcc_val_features.csv'),  header = None)\n",
    "\n",
    "train_mel_df = pd.read_csv(os.path.join(features_dir,f'{experiment}_mel_train_features.csv'),  header = None)\n",
    "val_mel_df = pd.read_csv(os.path.join(features_dir, f'{experiment}_mel_val_features.csv'),  header = None)\n",
    "\n",
    "train_scc_df = pd.read_csv(os.path.join(features_dir,f'{experiment}_scc_train_features.csv'),  header = None)\n",
    "val_scc_df = pd.read_csv(os.path.join(features_dir, f'{experiment}_scc_val_features.csv'),  header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the 'bcc', 'mel' and 'scc' dataframes\n",
    "train_features = pd.concat([train_bcc_df, train_mel_df, train_scc_df], ignore_index=True)\n",
    "val_features = pd.concat([val_bcc_df, val_mel_df, val_scc_df], ignore_index=True)\n",
    "\n",
    "# Shuffle the dataset\n",
    "train_features = train_features.sample(frac=1, random_state=42)\n",
    "val_features = val_features.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_features.iloc[:,:-1]\n",
    "y_train = train_features.iloc[:,-1]\n",
    "\n",
    "X_val = val_features.iloc[:,:-1]\n",
    "y_val = val_features.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the training data (mean = 0, std = 1)\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = pd.DataFrame(scaler.fit_transform(X_train))\n",
    "X_val_normalized = pd.DataFrame(scaler.transform(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the label column\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_val_encoded = encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(models, param_grids, X_train, y_train, X_val, y_val, scoring_metric='accuracy', cv=10):\n",
    "    all_models = []\n",
    "    \n",
    "    for model, param_grid in zip(models, param_grids):\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, verbose=2, scoring=scoring_metric)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        best_params = grid_search.best_params_\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # Store the best model and its parameters\n",
    "        all_models.append({'model': best_model, 'params': best_params})\n",
    "    \n",
    "    # Evaluate the best models on a separate validation set\n",
    "    models_report = []\n",
    "    for model_info in all_models:\n",
    "        model = model_info['model']\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        balanced_accuracy = balanced_accuracy_score(y_val, y_pred)\n",
    "        weighted_f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "        models_report = []\n",
    "        models_report.append({\n",
    "            'model': model, \n",
    "            'best_params': best_params, #model_info['params'], \n",
    "            'accuracy': accuracy, \n",
    "            'balanced_accuracy': balanced_accuracy,\n",
    "            'weighted_f1': weighted_f1})\n",
    "\n",
    "\n",
    "        conf_matrix = multilabel_confusion_matrix(y_val_encoded, y_pred)\n",
    "        classes = ['bcc', 'mel', 'scc']\n",
    "        for i, class_label in enumerate(classes):\n",
    "            tp = conf_matrix[i, 1, 1]\n",
    "            fp = conf_matrix[i, 0, 1]\n",
    "            fn = conf_matrix[i, 1, 0]\n",
    "            tn = conf_matrix[i, 0, 0]\n",
    "\n",
    "            specificity = tn / (tn + fp)\n",
    "            sensitivity = tp / (tp + fn)\n",
    "            precision = tp / (tp + fp)\n",
    "            f1 = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "\n",
    "            binary_true_labels = np.where(np.array(y_val) == i, 1, 0)\n",
    "            binary_predicted_labels = np.where(np.array(y_pred) == i, 1, 0)\n",
    "            fpr, tpr, _ = roc_curve(binary_true_labels, binary_predicted_labels)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "\n",
    "            models_report.append({\n",
    "                f'{class_label}_specificity': specificity,\n",
    "                f'{class_label}_sensitivity': sensitivity,\n",
    "                f'{class_label}_precision': precision,\n",
    "                f'{class_label}_f1': f1,\n",
    "                f'{class_label}_roc_auc': roc_auc\n",
    "            })\n",
    "\n",
    "        \n",
    "        #models_report.sort(key=lambda x: x['accuracy'], reverse=True)\n",
    "    \n",
    "    # return best_model, best_score, best_params, all_models\n",
    "    return models_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   2.7s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   3.6s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   3.0s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   2.4s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   1.5s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   1.1s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   2.2s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.8s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=  59.5s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=  43.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\master\\udg\\CAD\\project\\env\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=  40.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\master\\udg\\CAD\\project\\env\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\master\\udg\\CAD\\project\\env\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=  44.1s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   3.6s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   3.7s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   2.4s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\master\\udg\\CAD\\project\\env\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 2.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\master\\udg\\CAD\\project\\env\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\master\\udg\\CAD\\project\\env\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 3.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\master\\udg\\CAD\\project\\env\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\master\\udg\\CAD\\project\\env\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 2.8min\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   5.9s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   8.3s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   3.4s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   6.9s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   5.5s\n",
      "Model Report: [{'model': LogisticRegression(C=1, class_weight='balanced', multi_class='ovr',\n",
      "                   penalty='l1', solver='liblinear'), 'best_params': {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}, 'accuracy': 0.7724409448818897, 'balanced_accuracy': 0.6185914813462096, 'weighted_f1': 0.7676732965180896}, {'bcc_specificity': 0.8160621761658031, 'bcc_sensitivity': 0.8152610441767069, 'bcc_precision': 0.7408759124087592, 'bcc_f1': 0.7762906309751435, 'bcc_roc_auc': 0.8156616101712549}, {'mel_specificity': 0.831081081081081, 'mel_sensitivity': 0.8171091445427728, 'mel_precision': 0.8470948012232415, 'mel_f1': 0.8318318318318317, 'mel_roc_auc': 0.824095112811927}, {'scc_specificity': 0.9600340136054422, 'scc_sensitivity': 0.22340425531914893, 'scc_precision': 0.3088235294117647, 'scc_f1': 0.2592592592592593, 'scc_roc_auc': 0.5917191344622955}]\n"
     ]
    }
   ],
   "source": [
    "# Define the list of models and their respective hyperparameter grids\n",
    "models = [\n",
    "    #SVC(decision_function_shape='ovr', class_weight='balanced'),\n",
    "    LogisticRegression(multi_class = 'ovr', class_weight='balanced')\n",
    "    #KNeighborsClassifier(),\n",
    "    #RandomForestClassifier(),\n",
    "    #LinearDiscriminantAnalysis(),\n",
    "    #XGBClassifier()\n",
    "    ] \n",
    "        \n",
    "\n",
    "param_grids = [\n",
    "    #{'kernel':('linear', 'rbf'), 'C':[0.1, 1, 10], 'gamma':[0.001, 0.01, 0.1]}\n",
    "    {'penalty' : ['l1', 'l2'], 'C':[0.1, 1, 10], 'solver': ['liblinear']},\n",
    "    #{'n_neighbors': [3, 5, 7, 9], 'weights' : ['uniform', 'distance'], 'algorithm': ['ball_tree', 'kd_tree', 'brute'], 'p': [1, 2]}, \n",
    "    #{'n_estimators' : [50, 100, 200], 'max_depth': [3, 5, 7, 9], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}, # still takes a lot of time\n",
    "    #{'solver': ['svd', 'eigen'], 'shrinkage': [None, 'auto', 0.1, 0.5, 1.0]},\n",
    "    #{'max_depth': [4, 5], 'learning_rate': [0.1, 0.01], 'n_estimators': [200, 300], 'subsample': [0.5, 0.7, 1.0], 'colsample_bytree': [0.8, 0.9, 1.0]}\n",
    "\n",
    "]\n",
    "\n",
    "# Call the function to compare models and get the best one\n",
    "models_report = compare_models(models, param_grids, X_train_normalized, y_train_encoded, X_val_normalized, y_val_encoded, scoring_metric='f1_weighted', cv=5)\n",
    "\n",
    "# Save the best model to a file\n",
    "# best_model_filename = ROOT_PATH/'best_model.pkl'\n",
    "# with open(best_model_filename, 'wb') as file:\n",
    "#     pickle.dump(best_model, file)\n",
    "\n",
    "print(\"Model Report:\", models_report)\n",
    "# print(\"Best Score:\", best_score)\n",
    "# print(\"Best Params:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Report: [{'model': LogisticRegression(C=0.1, class_weight='balanced', multi_class='ovr'), 'best_params': {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}, 'accuracy': 0.7480314960629921, 'balanced_accuracy': 0.6123697703006844, 'weighted_f1': 0.754554307148425}, {'bcc_specificity': 0.8290155440414507, 'bcc_sensitivity': 0.7791164658634538, 'bcc_precision': 0.7461538461538462, 'bcc_f1': 0.7622789783889982, 'bcc_roc_auc': 0.8040660049524524}, {'mel_specificity': 0.8429054054054054, 'mel_sensitivity': 0.7920353982300885, 'mel_precision': 0.8523809523809524, 'mel_f1': 0.8211009174311927, 'mel_roc_auc': 0.8174704018177469}, {'scc_specificity': 0.91921768707483, 'scc_sensitivity': 0.26595744680851063, 'scc_precision': 0.20833333333333334, 'scc_f1': 0.2336448598130841, 'scc_roc_auc': 0.5925875669416703}]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Report:\", models_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model to a file\n",
    "best_model_filename = r'../models/best_model_multiclassSVM.pkl'\n",
    "with open(best_model_filename, 'wb') as file:\n",
    "     pickle.dump(best_model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
