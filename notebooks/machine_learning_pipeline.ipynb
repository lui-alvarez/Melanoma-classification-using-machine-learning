{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import sys\n",
    "sys.path.append('../helpers/')\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "from feature_selection import FeatureSelection\n",
    "\n",
    "select_feature = FeatureSelection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(models, param_grids, X_train, y_train, X_val, y_val, scoring_metric='accuracy', cv=10):\n",
    "    all_models = []\n",
    "    \n",
    "    for model, param_grid in zip(models, param_grids):\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, verbose=2, scoring=scoring_metric)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        best_params = grid_search.best_params_\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # Store the best model and its parameters\n",
    "        all_models.append({'model': best_model, 'params': best_params})\n",
    "    \n",
    "    # Evaluate the best models on a separate validation set\n",
    "    models_report = []\n",
    "    for model_info in all_models:\n",
    "        model = model_info['model']\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        # Accuracy score\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        \n",
    "        # F1 score\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "        # Confusion Matrix\n",
    "        conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "        true_positives = conf_matrix[1, 1]\n",
    "        true_negatives = conf_matrix[0, 0]\n",
    "        false_positives = conf_matrix[0, 1]\n",
    "        false_negatives = conf_matrix[1, 0]\n",
    "\n",
    "        # Sensitivity (True Positive Rate or Recall)\n",
    "        sensitivity = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "        # Specificity (True Negative Rate)\n",
    "        specificity = true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "        # Precision\n",
    "        precision = true_positives / (true_positives + false_positives)\n",
    "\n",
    "        models_report.append({\n",
    "            'model': model, \n",
    "            'best_params': model_info['params'], \n",
    "            'accuracy': accuracy, \n",
    "            'f1': f1, \n",
    "            'sensitivity': sensitivity, \n",
    "            'specificity': specificity,\n",
    "            'precision': precision})\n",
    "        \n",
    "        models_report.sort(key=lambda x: x['accuracy'], reverse=True)\n",
    "    \n",
    "    # return best_model, best_score, best_params, all_models\n",
    "    return models_report\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = Path(Path(os.getcwd())/\"../output/features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment              = 3\n",
    "\n",
    "train_nevus_df = pd.read_csv(ROOT_PATH/f'{experiment}_nevus_train_features.csv',  header = None)\n",
    "val_nevus_df = pd.read_csv(ROOT_PATH/f'{experiment}_nevus_val_features.csv',  header = None)\n",
    "\n",
    "train_others_df = pd.read_csv(ROOT_PATH/f'{experiment}_others_train_features.csv',  header = None)\n",
    "val_others_df = pd.read_csv(ROOT_PATH/f'{experiment}_others_val_features.csv',  header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.010586</td>\n",
       "      <td>3.627673</td>\n",
       "      <td>0.032592</td>\n",
       "      <td>5.590849</td>\n",
       "      <td>12.962111</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.009306</td>\n",
       "      <td>3.054257</td>\n",
       "      <td>0.026076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017826</td>\n",
       "      <td>0.016285</td>\n",
       "      <td>0.018685</td>\n",
       "      <td>0.018685</td>\n",
       "      <td>0.020074</td>\n",
       "      <td>0.014141</td>\n",
       "      <td>0.007319</td>\n",
       "      <td>0.073348</td>\n",
       "      <td>0.347937</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.006406</td>\n",
       "      <td>1.990036</td>\n",
       "      <td>0.014412</td>\n",
       "      <td>6.612989</td>\n",
       "      <td>2.789321</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.006059</td>\n",
       "      <td>2.359529</td>\n",
       "      <td>0.013304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015360</td>\n",
       "      <td>0.012883</td>\n",
       "      <td>0.020381</td>\n",
       "      <td>0.017023</td>\n",
       "      <td>0.019762</td>\n",
       "      <td>0.011142</td>\n",
       "      <td>0.007871</td>\n",
       "      <td>0.084335</td>\n",
       "      <td>0.301383</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>4.485626</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>5.261551</td>\n",
       "      <td>20.449217</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011281</td>\n",
       "      <td>3.832070</td>\n",
       "      <td>0.036486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015440</td>\n",
       "      <td>0.013021</td>\n",
       "      <td>0.018877</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.023338</td>\n",
       "      <td>0.015481</td>\n",
       "      <td>0.008381</td>\n",
       "      <td>0.089910</td>\n",
       "      <td>0.400306</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.009731</td>\n",
       "      <td>3.655664</td>\n",
       "      <td>0.028149</td>\n",
       "      <td>5.784594</td>\n",
       "      <td>13.168047</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>2.961299</td>\n",
       "      <td>0.017002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.016330</td>\n",
       "      <td>0.018767</td>\n",
       "      <td>0.017930</td>\n",
       "      <td>0.019574</td>\n",
       "      <td>0.013581</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>0.073663</td>\n",
       "      <td>0.340263</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.012468</td>\n",
       "      <td>4.113493</td>\n",
       "      <td>0.043701</td>\n",
       "      <td>5.079543</td>\n",
       "      <td>16.822559</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.009250</td>\n",
       "      <td>3.045493</td>\n",
       "      <td>0.025811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013619</td>\n",
       "      <td>0.015311</td>\n",
       "      <td>0.017493</td>\n",
       "      <td>0.019781</td>\n",
       "      <td>0.023619</td>\n",
       "      <td>0.019993</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.087644</td>\n",
       "      <td>0.432200</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4          5         6    \\\n",
       "0  0.003906  0.010586  3.627673  0.032592  5.590849  12.962111  0.003906   \n",
       "1  0.003906  0.006406  1.990036  0.014412  6.612989   2.789321  0.003906   \n",
       "2  0.003906  0.012463  4.485626  0.043669  5.261551  20.449217  0.003906   \n",
       "3  0.003906  0.009731  3.655664  0.028149  5.784594  13.168047  0.003906   \n",
       "4  0.003906  0.012468  4.113493  0.043701  5.079543  16.822559  0.003906   \n",
       "\n",
       "        7         8         9    ...       95        96        97        98   \\\n",
       "0  0.009306  3.054257  0.026076  ...  0.017826  0.016285  0.018685  0.018685   \n",
       "1  0.006059  2.359529  0.013304  ...  0.015360  0.012883  0.020381  0.017023   \n",
       "2  0.011281  3.832070  0.036486  ...  0.015440  0.013021  0.018877  0.019531   \n",
       "3  0.007152  2.961299  0.017002  ...  0.018000  0.016330  0.018767  0.017930   \n",
       "4  0.009250  3.045493  0.025811  ...  0.013619  0.015311  0.017493  0.019781   \n",
       "\n",
       "        99        100       101       102       103  104  \n",
       "0  0.020074  0.014141  0.007319  0.073348  0.347937  0.0  \n",
       "1  0.019762  0.011142  0.007871  0.084335  0.301383  0.0  \n",
       "2  0.023338  0.015481  0.008381  0.089910  0.400306  0.0  \n",
       "3  0.019574  0.013581  0.008611  0.073663  0.340263  0.0  \n",
       "4  0.023619  0.019993  0.012359  0.087644  0.432200  0.0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nevus_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7725, 105)\n"
     ]
    }
   ],
   "source": [
    "print(train_nevus_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.004846</td>\n",
       "      <td>0.866540</td>\n",
       "      <td>0.009917</td>\n",
       "      <td>6.821035</td>\n",
       "      <td>-0.845557</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>0.569717</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007885</td>\n",
       "      <td>0.008702</td>\n",
       "      <td>0.010465</td>\n",
       "      <td>0.013727</td>\n",
       "      <td>0.020567</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.016177</td>\n",
       "      <td>0.081679</td>\n",
       "      <td>0.478398</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.009304</td>\n",
       "      <td>3.110399</td>\n",
       "      <td>0.026066</td>\n",
       "      <td>5.752192</td>\n",
       "      <td>8.962885</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.006753</td>\n",
       "      <td>2.091162</td>\n",
       "      <td>0.015580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014958</td>\n",
       "      <td>0.015119</td>\n",
       "      <td>0.016079</td>\n",
       "      <td>0.017165</td>\n",
       "      <td>0.019433</td>\n",
       "      <td>0.016565</td>\n",
       "      <td>0.011448</td>\n",
       "      <td>0.065283</td>\n",
       "      <td>0.367760</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011715</td>\n",
       "      <td>3.305057</td>\n",
       "      <td>0.039042</td>\n",
       "      <td>4.986072</td>\n",
       "      <td>9.886728</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.009415</td>\n",
       "      <td>2.738572</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.006917</td>\n",
       "      <td>0.008635</td>\n",
       "      <td>0.012485</td>\n",
       "      <td>0.021433</td>\n",
       "      <td>0.026533</td>\n",
       "      <td>0.019844</td>\n",
       "      <td>0.092346</td>\n",
       "      <td>0.538815</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>2.658633</td>\n",
       "      <td>0.016504</td>\n",
       "      <td>6.566395</td>\n",
       "      <td>6.551500</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>2.660783</td>\n",
       "      <td>0.011336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018185</td>\n",
       "      <td>0.011881</td>\n",
       "      <td>0.017308</td>\n",
       "      <td>0.009706</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.004329</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.122135</td>\n",
       "      <td>0.138162</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.008983</td>\n",
       "      <td>3.295780</td>\n",
       "      <td>0.024566</td>\n",
       "      <td>6.029446</td>\n",
       "      <td>10.991496</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.007163</td>\n",
       "      <td>2.242579</td>\n",
       "      <td>0.017041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>0.012560</td>\n",
       "      <td>0.016387</td>\n",
       "      <td>0.014988</td>\n",
       "      <td>0.017108</td>\n",
       "      <td>0.012425</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.091177</td>\n",
       "      <td>0.312458</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4          5         6    \\\n",
       "0  0.003906  0.004846  0.866540  0.009917  6.821035  -0.845557  0.003906   \n",
       "1  0.003906  0.009304  3.110399  0.026066  5.752192   8.962885  0.003906   \n",
       "2  0.003906  0.011715  3.305057  0.039042  4.986072   9.886728  0.003906   \n",
       "3  0.003906  0.007015  2.658633  0.016504  6.566395   6.551500  0.003906   \n",
       "4  0.003906  0.008983  3.295780  0.024566  6.029446  10.991496  0.003906   \n",
       "\n",
       "        7         8         9    ...       95        96        97        98   \\\n",
       "0  0.004115  0.569717  0.008242  ...  0.007885  0.008702  0.010465  0.013727   \n",
       "1  0.006753  2.091162  0.015580  ...  0.014958  0.015119  0.016079  0.017165   \n",
       "2  0.009415  2.738572  0.026600  ...  0.005950  0.006917  0.008635  0.012485   \n",
       "3  0.005387  2.660783  0.011336  ...  0.018185  0.011881  0.017308  0.009706   \n",
       "4  0.007163  2.242579  0.017041  ...  0.014727  0.012560  0.016387  0.014988   \n",
       "\n",
       "        99        100       101       102       103  104  \n",
       "0  0.020567  0.022927  0.016177  0.081679  0.478398  1.0  \n",
       "1  0.019433  0.016565  0.011448  0.065283  0.367760  1.0  \n",
       "2  0.021433  0.026533  0.019844  0.092346  0.538815  1.0  \n",
       "3  0.010900  0.004329  0.002658  0.122135  0.138162  1.0  \n",
       "4  0.017108  0.012425  0.007321  0.091177  0.312458  1.0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_others_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7470, 105)\n"
     ]
    }
   ],
   "source": [
    "print(train_others_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.008967</td>\n",
       "      <td>3.056522</td>\n",
       "      <td>0.024493</td>\n",
       "      <td>5.963221</td>\n",
       "      <td>8.973989</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.009085</td>\n",
       "      <td>3.327701</td>\n",
       "      <td>0.025035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015652</td>\n",
       "      <td>0.014783</td>\n",
       "      <td>0.015896</td>\n",
       "      <td>0.017254</td>\n",
       "      <td>0.020160</td>\n",
       "      <td>0.016035</td>\n",
       "      <td>0.009071</td>\n",
       "      <td>0.069790</td>\n",
       "      <td>0.385342</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.008102</td>\n",
       "      <td>2.151166</td>\n",
       "      <td>0.020711</td>\n",
       "      <td>5.857988</td>\n",
       "      <td>3.186463</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005606</td>\n",
       "      <td>1.715020</td>\n",
       "      <td>0.011951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014693</td>\n",
       "      <td>0.015052</td>\n",
       "      <td>0.017415</td>\n",
       "      <td>0.018481</td>\n",
       "      <td>0.021189</td>\n",
       "      <td>0.018237</td>\n",
       "      <td>0.010619</td>\n",
       "      <td>0.075759</td>\n",
       "      <td>0.398167</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.006051</td>\n",
       "      <td>2.071912</td>\n",
       "      <td>0.013278</td>\n",
       "      <td>6.598399</td>\n",
       "      <td>3.991298</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.004471</td>\n",
       "      <td>1.439740</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015067</td>\n",
       "      <td>0.013090</td>\n",
       "      <td>0.016567</td>\n",
       "      <td>0.016644</td>\n",
       "      <td>0.019877</td>\n",
       "      <td>0.014017</td>\n",
       "      <td>0.009719</td>\n",
       "      <td>0.074842</td>\n",
       "      <td>0.349240</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>3.324888</td>\n",
       "      <td>0.012905</td>\n",
       "      <td>6.953759</td>\n",
       "      <td>12.320268</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>2.646637</td>\n",
       "      <td>0.011996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014617</td>\n",
       "      <td>0.011673</td>\n",
       "      <td>0.019523</td>\n",
       "      <td>0.016050</td>\n",
       "      <td>0.019467</td>\n",
       "      <td>0.012125</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>0.090821</td>\n",
       "      <td>0.337288</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>2.653999</td>\n",
       "      <td>0.018845</td>\n",
       "      <td>6.362201</td>\n",
       "      <td>5.720409</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.007604</td>\n",
       "      <td>2.771503</td>\n",
       "      <td>0.018708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015430</td>\n",
       "      <td>0.016370</td>\n",
       "      <td>0.018485</td>\n",
       "      <td>0.020096</td>\n",
       "      <td>0.022307</td>\n",
       "      <td>0.018070</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.079141</td>\n",
       "      <td>0.393970</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4          5         6    \\\n",
       "0  0.003906  0.008967  3.056522  0.024493  5.963221   8.973989  0.003906   \n",
       "1  0.003906  0.008102  2.151166  0.020711  5.857988   3.186463  0.003906   \n",
       "2  0.003906  0.006051  2.071912  0.013278  6.598399   3.991298  0.003906   \n",
       "3  0.003906  0.005929  3.324888  0.012905  6.953759  12.320268  0.003906   \n",
       "4  0.003906  0.007639  2.653999  0.018845  6.362201   5.720409  0.003906   \n",
       "\n",
       "        7         8         9    ...       95        96        97        98   \\\n",
       "0  0.009085  3.327701  0.025035  ...  0.015652  0.014783  0.015896  0.017254   \n",
       "1  0.005606  1.715020  0.011951  ...  0.014693  0.015052  0.017415  0.018481   \n",
       "2  0.004471  1.439740  0.009024  ...  0.015067  0.013090  0.016567  0.016644   \n",
       "3  0.005621  2.646637  0.011996  ...  0.014617  0.011673  0.019523  0.016050   \n",
       "4  0.007604  2.771503  0.018708  ...  0.015430  0.016370  0.018485  0.020096   \n",
       "\n",
       "        99        100       101       102       103  104  \n",
       "0  0.020160  0.016035  0.009071  0.069790  0.385342  0.0  \n",
       "1  0.021189  0.018237  0.010619  0.075759  0.398167  0.0  \n",
       "2  0.019877  0.014017  0.009719  0.074842  0.349240  0.0  \n",
       "3  0.019467  0.012125  0.007575  0.090821  0.337288  0.0  \n",
       "4  0.022307  0.018070  0.010526  0.079141  0.393970  0.0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_nevus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1931, 105)\n"
     ]
    }
   ],
   "source": [
    "print(val_nevus_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.007101</td>\n",
       "      <td>2.898542</td>\n",
       "      <td>0.016816</td>\n",
       "      <td>6.486648</td>\n",
       "      <td>9.094543</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005382</td>\n",
       "      <td>3.192499</td>\n",
       "      <td>0.011320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009160</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>0.011321</td>\n",
       "      <td>0.014533</td>\n",
       "      <td>0.012165</td>\n",
       "      <td>0.006221</td>\n",
       "      <td>0.077381</td>\n",
       "      <td>0.331912</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.007871</td>\n",
       "      <td>2.050016</td>\n",
       "      <td>0.019765</td>\n",
       "      <td>5.915789</td>\n",
       "      <td>2.870014</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.006258</td>\n",
       "      <td>1.391339</td>\n",
       "      <td>0.013932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.016711</td>\n",
       "      <td>0.016604</td>\n",
       "      <td>0.015752</td>\n",
       "      <td>0.015133</td>\n",
       "      <td>0.010811</td>\n",
       "      <td>0.006707</td>\n",
       "      <td>0.049419</td>\n",
       "      <td>0.249822</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.008371</td>\n",
       "      <td>2.861103</td>\n",
       "      <td>0.021845</td>\n",
       "      <td>6.242858</td>\n",
       "      <td>7.131025</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>2.735013</td>\n",
       "      <td>0.012693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016150</td>\n",
       "      <td>0.013227</td>\n",
       "      <td>0.019079</td>\n",
       "      <td>0.014310</td>\n",
       "      <td>0.015823</td>\n",
       "      <td>0.008842</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>0.083383</td>\n",
       "      <td>0.233371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>3.394838</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>6.453406</td>\n",
       "      <td>15.632707</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>3.923633</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014479</td>\n",
       "      <td>0.012450</td>\n",
       "      <td>0.018763</td>\n",
       "      <td>0.015775</td>\n",
       "      <td>0.018396</td>\n",
       "      <td>0.012131</td>\n",
       "      <td>0.007452</td>\n",
       "      <td>0.094242</td>\n",
       "      <td>0.297619</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.008143</td>\n",
       "      <td>2.462333</td>\n",
       "      <td>0.020880</td>\n",
       "      <td>6.143307</td>\n",
       "      <td>4.536312</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>1.311196</td>\n",
       "      <td>0.010829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014331</td>\n",
       "      <td>0.012035</td>\n",
       "      <td>0.014646</td>\n",
       "      <td>0.015773</td>\n",
       "      <td>0.018304</td>\n",
       "      <td>0.012823</td>\n",
       "      <td>0.006744</td>\n",
       "      <td>0.071442</td>\n",
       "      <td>0.349892</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4          5         6    \\\n",
       "0  0.003906  0.007101  2.898542  0.016816  6.486648   9.094543  0.003906   \n",
       "1  0.003906  0.007871  2.050016  0.019765  5.915789   2.870014  0.003906   \n",
       "2  0.003906  0.008371  2.861103  0.021845  6.242858   7.131025  0.003906   \n",
       "3  0.003906  0.007507  3.394838  0.018333  6.453406  15.632707  0.003906   \n",
       "4  0.003906  0.008143  2.462333  0.020880  6.143307   4.536312  0.003906   \n",
       "\n",
       "        7         8         9    ...       95        96        97        98   \\\n",
       "0  0.005382  3.192499  0.011320  ...  0.009160  0.008281  0.009402  0.011321   \n",
       "1  0.006258  1.391339  0.013932  ...  0.018393  0.016711  0.016604  0.015752   \n",
       "2  0.005859  2.735013  0.012693  ...  0.016150  0.013227  0.019079  0.014310   \n",
       "3  0.006473  3.923633  0.014634  ...  0.014479  0.012450  0.018763  0.015775   \n",
       "4  0.005200  1.311196  0.010829  ...  0.014331  0.012035  0.014646  0.015773   \n",
       "\n",
       "        99        100       101       102       103  104  \n",
       "0  0.014533  0.012165  0.006221  0.077381  0.331912  1.0  \n",
       "1  0.015133  0.010811  0.006707  0.049419  0.249822  1.0  \n",
       "2  0.015823  0.008842  0.005150  0.083383  0.233371  1.0  \n",
       "3  0.018396  0.012131  0.007452  0.094242  0.297619  1.0  \n",
       "4  0.018304  0.012823  0.006744  0.071442  0.349892  1.0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_others_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1865, 105)\n"
     ]
    }
   ],
   "source": [
    "print(val_others_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the 'nevus' and 'others' dataframes\n",
    "train_features = pd.concat([train_nevus_df, train_others_df], ignore_index=True)\n",
    "val_features = pd.concat([val_nevus_df, val_others_df], ignore_index=True)\n",
    "\n",
    "# Shuffle the dataset\n",
    "train_features = train_features.sample(frac=1, random_state=42)\n",
    "val_features = val_features.sample(frac=1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>2.476268</td>\n",
       "      <td>0.020084</td>\n",
       "      <td>6.083987</td>\n",
       "      <td>5.244693</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>2.056992</td>\n",
       "      <td>0.013737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014026</td>\n",
       "      <td>0.016085</td>\n",
       "      <td>0.016507</td>\n",
       "      <td>0.017385</td>\n",
       "      <td>0.018948</td>\n",
       "      <td>0.020730</td>\n",
       "      <td>0.016674</td>\n",
       "      <td>0.009863</td>\n",
       "      <td>0.074107</td>\n",
       "      <td>0.383415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3078</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>4.537892</td>\n",
       "      <td>0.051631</td>\n",
       "      <td>4.893095</td>\n",
       "      <td>20.649601</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011992</td>\n",
       "      <td>4.030384</td>\n",
       "      <td>0.040723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012302</td>\n",
       "      <td>0.016102</td>\n",
       "      <td>0.014113</td>\n",
       "      <td>0.019015</td>\n",
       "      <td>0.019960</td>\n",
       "      <td>0.023742</td>\n",
       "      <td>0.015706</td>\n",
       "      <td>0.008215</td>\n",
       "      <td>0.085862</td>\n",
       "      <td>0.402779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.010601</td>\n",
       "      <td>3.147719</td>\n",
       "      <td>0.032673</td>\n",
       "      <td>5.328911</td>\n",
       "      <td>8.852881</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011670</td>\n",
       "      <td>3.960868</td>\n",
       "      <td>0.038769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012119</td>\n",
       "      <td>0.014759</td>\n",
       "      <td>0.016548</td>\n",
       "      <td>0.018219</td>\n",
       "      <td>0.020744</td>\n",
       "      <td>0.022841</td>\n",
       "      <td>0.018789</td>\n",
       "      <td>0.011419</td>\n",
       "      <td>0.084244</td>\n",
       "      <td>0.417467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>2.345179</td>\n",
       "      <td>0.021213</td>\n",
       "      <td>5.828956</td>\n",
       "      <td>4.650671</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>2.026683</td>\n",
       "      <td>0.016731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016296</td>\n",
       "      <td>0.019978</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.019419</td>\n",
       "      <td>0.019122</td>\n",
       "      <td>0.018741</td>\n",
       "      <td>0.011352</td>\n",
       "      <td>0.006978</td>\n",
       "      <td>0.068337</td>\n",
       "      <td>0.319848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.007149</td>\n",
       "      <td>1.860630</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>6.220841</td>\n",
       "      <td>2.048289</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>2.049136</td>\n",
       "      <td>0.017134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014196</td>\n",
       "      <td>0.016559</td>\n",
       "      <td>0.016563</td>\n",
       "      <td>0.017363</td>\n",
       "      <td>0.018485</td>\n",
       "      <td>0.019930</td>\n",
       "      <td>0.015433</td>\n",
       "      <td>0.008863</td>\n",
       "      <td>0.071107</td>\n",
       "      <td>0.369211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4          5         6    \\\n",
       "298   0.003906  0.007949  2.476268  0.020084  6.083987   5.244693  0.003906   \n",
       "3078  0.003906  0.013654  4.537892  0.051631  4.893095  20.649601  0.003906   \n",
       "1361  0.003906  0.010601  3.147719  0.032673  5.328911   8.852881  0.003906   \n",
       "2711  0.003906  0.008222  2.345179  0.021213  5.828956   4.650671  0.003906   \n",
       "2416  0.003906  0.007149  1.860630  0.016991  6.220841   2.048289  0.003906   \n",
       "\n",
       "           7         8         9    ...       94        95        96   \\\n",
       "298   0.006197  2.056992  0.013737  ...  0.014026  0.016085  0.016507   \n",
       "3078  0.011992  4.030384  0.040723  ...  0.012302  0.016102  0.014113   \n",
       "1361  0.011670  3.960868  0.038769  ...  0.012119  0.014759  0.016548   \n",
       "2711  0.007078  2.026683  0.016731  ...  0.016296  0.019978  0.018000   \n",
       "2416  0.007188  2.049136  0.017134  ...  0.014196  0.016559  0.016563   \n",
       "\n",
       "           97        98        99        100       101       102       103  \n",
       "298   0.017385  0.018948  0.020730  0.016674  0.009863  0.074107  0.383415  \n",
       "3078  0.019015  0.019960  0.023742  0.015706  0.008215  0.085862  0.402779  \n",
       "1361  0.018219  0.020744  0.022841  0.018789  0.011419  0.084244  0.417467  \n",
       "2711  0.019419  0.019122  0.018741  0.011352  0.006978  0.068337  0.319848  \n",
       "2416  0.017363  0.018485  0.019930  0.015433  0.008863  0.071107  0.369211  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_features.iloc[:,:-1]\n",
    "y_train = train_features.iloc[:,-1]\n",
    "\n",
    "X_val = val_features.iloc[:,:-1]\n",
    "y_val = val_features.iloc[:,-1]\n",
    "\n",
    "X_val.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, selected_feature_indices  = select_feature.max_entropy_feature_selection(X_train, y_train)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val = X_val.iloc[:, selected_feature_indices]\n",
    "# X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the training data (mean = 0, std = 1)\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = pd.DataFrame(scaler.fit_transform(X_train))\n",
    "X_val_normalized = pd.DataFrame(scaler.transform(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the label column\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_val_encoded = encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15195, 104) (15195,) (3796, 104) (3796,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_normalized.shape, y_train_encoded.shape, X_val_normalized.shape, y_val_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   7.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   8.7s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   8.2s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   7.5s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   6.5s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   8.9s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   8.4s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   8.3s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  10.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  11.9s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   7.3s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   9.7s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   9.8s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   6.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   6.8s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   8.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   7.8s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   8.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   7.7s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   8.2s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   7.2s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   6.9s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   6.5s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   6.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   6.7s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=  10.2s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   9.8s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   9.9s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   9.9s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=  10.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=  13.9s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=  14.4s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=  14.5s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=  13.6s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=  14.4s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   7.5s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   7.5s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   7.1s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   7.2s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   7.3s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=  14.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=  14.5s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=  14.6s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=  14.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=  17.2s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   8.6s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   8.5s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   8.4s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   8.2s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   8.1s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=  15.6s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=  17.2s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=  16.3s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=  16.3s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=  15.8s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  12.7s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  12.4s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  13.2s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  16.3s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  12.9s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time= 1.1min\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time= 1.1min\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time= 1.1min\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time= 1.1min\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time= 1.1min\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   6.7s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   6.8s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   6.7s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   6.9s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   6.8s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time= 1.2min\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time= 1.1min\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time= 1.1min\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time= 1.0min\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time= 1.1min\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   8.1s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   7.7s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   7.5s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   7.9s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   7.8s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time= 1.1min\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time= 1.1min\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time= 1.1min\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time= 1.1min\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time= 1.1min\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=  22.6s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=  22.2s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=  22.5s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=  21.9s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=  22.6s\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..........C=0.1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ..........C=0.1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ..........C=0.1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ..........C=0.1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ..........C=0.1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=0.1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ......................C=0.1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ......................C=0.1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ......................C=0.1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ......................C=0.1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=   1.3s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=   1.3s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..........C=0.1, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ..........C=0.1, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ..........C=0.1, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ..........C=0.1, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ..........C=0.1, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=0.1, penalty=l2, solver=sag; total time=   0.8s\n",
      "[CV] END ......................C=0.1, penalty=l2, solver=sag; total time=   0.7s\n",
      "[CV] END ......................C=0.1, penalty=l2, solver=sag; total time=   0.8s\n",
      "[CV] END ......................C=0.1, penalty=l2, solver=sag; total time=   0.8s\n",
      "[CV] END ......................C=0.1, penalty=l2, solver=sag; total time=   0.9s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   1.0s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   1.0s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   1.0s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   1.0s\n",
      "[CV] END ............C=0.1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=0.1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=0.1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=0.1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=0.1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=0.1, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ..C=0.1, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ..C=0.1, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ..C=0.1, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ..C=0.1, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ..............C=0.1, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ..............C=0.1, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ..............C=0.1, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ..............C=0.1, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ..............C=0.1, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END .............C=0.1, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END .............C=0.1, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END .............C=0.1, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END .............C=0.1, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END .............C=0.1, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END ..................C=0.1, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..................C=0.1, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..................C=0.1, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..................C=0.1, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..................C=0.1, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=0.1, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ........C=0.1, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ........C=0.1, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ........C=0.1, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ........C=0.1, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ....................C=0.1, penalty=None, solver=sag; total time=   0.8s\n",
      "[CV] END ....................C=0.1, penalty=None, solver=sag; total time=   0.8s\n",
      "[CV] END ....................C=0.1, penalty=None, solver=sag; total time=   0.8s\n",
      "[CV] END ....................C=0.1, penalty=None, solver=sag; total time=   0.8s\n",
      "[CV] END ....................C=0.1, penalty=None, solver=sag; total time=   0.8s\n",
      "[CV] END ...................C=0.1, penalty=None, solver=saga; total time=   0.9s\n",
      "[CV] END ...................C=0.1, penalty=None, solver=saga; total time=   0.9s\n",
      "[CV] END ...................C=0.1, penalty=None, solver=saga; total time=   0.9s\n",
      "[CV] END ...................C=0.1, penalty=None, solver=saga; total time=   0.9s\n",
      "[CV] END ...................C=0.1, penalty=None, solver=saga; total time=   0.8s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ........................C=1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ........................C=1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ........................C=1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ........................C=1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ........................C=1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=   1.3s\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=   1.3s\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ............C=1, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ........................C=1, penalty=l2, solver=sag; total time=   0.8s\n",
      "[CV] END ........................C=1, penalty=l2, solver=sag; total time=   0.8s\n",
      "[CV] END ........................C=1, penalty=l2, solver=sag; total time=   0.8s\n",
      "[CV] END ........................C=1, penalty=l2, solver=sag; total time=   0.8s\n",
      "[CV] END ........................C=1, penalty=l2, solver=sag; total time=   0.8s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END ..............C=1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..............C=1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..............C=1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..............C=1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..............C=1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=1, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ....C=1, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ....C=1, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ....C=1, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ....C=1, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ................C=1, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ................C=1, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ................C=1, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ................C=1, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ................C=1, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ...............C=1, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END ...............C=1, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END ...............C=1, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END ...............C=1, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END ...............C=1, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END ....................C=1, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=1, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=1, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=1, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=1, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..........C=1, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ..........C=1, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ..........C=1, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ..........C=1, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ..........C=1, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=None, solver=sag; total time=   0.8s\n",
      "[CV] END ......................C=1, penalty=None, solver=sag; total time=   0.8s\n",
      "[CV] END ......................C=1, penalty=None, solver=sag; total time=   0.8s\n",
      "[CV] END ......................C=1, penalty=None, solver=sag; total time=   0.8s\n",
      "[CV] END ......................C=1, penalty=None, solver=sag; total time=   0.8s\n",
      "[CV] END .....................C=1, penalty=None, solver=saga; total time=   0.9s\n",
      "[CV] END .....................C=1, penalty=None, solver=saga; total time=   0.9s\n",
      "[CV] END .....................C=1, penalty=None, solver=saga; total time=   0.9s\n",
      "[CV] END .....................C=1, penalty=None, solver=saga; total time=   0.9s\n",
      "[CV] END .....................C=1, penalty=None, solver=saga; total time=   0.9s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l1, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .......................C=10, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END .......................C=10, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END .......................C=10, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END .......................C=10, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END .......................C=10, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=   1.3s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=   1.3s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=   1.3s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...........C=10, penalty=l2, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .......................C=10, penalty=l2, solver=sag; total time=   0.8s\n",
      "[CV] END .......................C=10, penalty=l2, solver=sag; total time=   0.8s\n",
      "[CV] END .......................C=10, penalty=l2, solver=sag; total time=   0.8s\n",
      "[CV] END .......................C=10, penalty=l2, solver=sag; total time=   0.9s\n",
      "[CV] END .......................C=10, penalty=l2, solver=sag; total time=   0.8s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END .............C=10, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .............C=10, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .............C=10, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .............C=10, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .............C=10, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...C=10, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...C=10, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...C=10, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...C=10, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...C=10, penalty=elasticnet, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END ...............C=10, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ...............C=10, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ...............C=10, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ...............C=10, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ...............C=10, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ..............C=10, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END ..............C=10, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END ..............C=10, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END ..............C=10, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END ..............C=10, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END ...................C=10, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=10, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=10, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=10, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=10, penalty=None, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=None, solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=None, solver=sag; total time=   0.8s\n",
      "[CV] END .....................C=10, penalty=None, solver=sag; total time=   0.8s\n",
      "[CV] END .....................C=10, penalty=None, solver=sag; total time=   0.8s\n",
      "[CV] END .....................C=10, penalty=None, solver=sag; total time=   0.8s\n",
      "[CV] END .....................C=10, penalty=None, solver=sag; total time=   0.7s\n",
      "[CV] END ....................C=10, penalty=None, solver=saga; total time=   0.9s\n",
      "[CV] END ....................C=10, penalty=None, solver=saga; total time=   0.8s\n",
      "[CV] END ....................C=10, penalty=None, solver=saga; total time=   0.9s\n",
      "[CV] END ....................C=10, penalty=None, solver=saga; total time=   0.9s\n",
      "[CV] END ....................C=10, penalty=None, solver=saga; total time=   0.9s\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   3.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   3.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   3.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   3.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform; total time=   3.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   3.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   3.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   2.9s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   3.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance; total time=   3.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   3.4s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   3.6s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   3.4s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   3.6s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform; total time=   3.4s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   3.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   3.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   3.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   3.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance; total time=   3.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   3.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   3.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   3.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   3.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform; total time=   3.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   3.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   4.7s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   5.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   6.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance; total time=   3.5s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   4.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   4.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   3.6s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   4.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform; total time=   4.9s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   5.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   3.9s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   5.1s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   3.6s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance; total time=   3.5s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   3.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   3.5s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   3.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   3.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=uniform; total time=   3.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   3.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   3.4s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   4.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   3.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=1, weights=distance; total time=   3.6s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   3.5s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   5.7s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   5.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   5.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=uniform; total time=   6.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   4.8s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   4.7s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   4.5s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   4.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=7, p=2, weights=distance; total time=   5.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   4.7s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   4.8s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   5.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   7.4s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=uniform; total time=   4.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   4.5s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   3.7s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   3.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   4.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=1, weights=distance; total time=   3.3s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   3.6s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   3.4s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   3.7s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   3.5s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=uniform; total time=   3.7s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   3.4s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   5.2s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   4.0s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   4.7s\n",
      "[CV] END algorithm=ball_tree, n_neighbors=9, p=2, weights=distance; total time=   4.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   4.9s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   5.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   7.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   7.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform; total time=   5.7s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   8.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   5.6s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   4.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   4.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance; total time=   3.8s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   3.9s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   3.8s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   3.7s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   3.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform; total time=   3.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   3.7s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   3.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   3.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   3.9s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance; total time=   2.8s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   4.7s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   5.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   5.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   6.2s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform; total time=   3.9s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   3.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   2.9s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   3.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   3.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance; total time=   3.9s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   3.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   3.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   3.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   3.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform; total time=   4.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   2.7s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   4.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   4.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   4.6s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance; total time=   4.6s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   6.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   6.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   3.8s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   5.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=uniform; total time=   3.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   2.9s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   3.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   3.8s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   4.6s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=1, weights=distance; total time=   3.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   3.9s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   4.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   3.6s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   4.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=uniform; total time=   3.9s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   3.7s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   3.9s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   3.6s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   3.8s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=7, p=2, weights=distance; total time=   3.6s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   4.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   4.1s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   4.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   3.9s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=uniform; total time=   4.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   4.3s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   4.0s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   3.9s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   3.9s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=1, weights=distance; total time=   3.7s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   3.4s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   3.8s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   3.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   3.7s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=uniform; total time=   3.8s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   3.7s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   3.6s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   3.5s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   3.6s\n",
      "[CV] END algorithm=kd_tree, n_neighbors=9, p=2, weights=distance; total time=   3.5s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.8s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.6s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.7s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.6s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=uniform; total time=   0.7s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.5s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.5s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=1, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=3, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.7s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.7s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.7s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.7s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=uniform; total time=   0.7s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=1, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.8s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.7s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.8s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.7s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=uniform; total time=   0.7s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=1, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=7, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   1.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.7s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.7s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.7s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=uniform; total time=   0.7s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=1, weights=distance; total time=   0.6s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=brute, n_neighbors=9, p=2, weights=distance; total time=   0.0s\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   3.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   2.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   2.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   2.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   2.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  10.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  11.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  14.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  12.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  11.1s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   2.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   2.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   2.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   2.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   2.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   5.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   5.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   5.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   7.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   7.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  15.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  17.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  12.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  10.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  10.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   2.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   2.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   2.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   2.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   2.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   5.1s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   5.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   5.1s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   5.1s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   5.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  10.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  10.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  10.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  10.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  10.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   2.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   2.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   2.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   2.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   2.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   5.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   5.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   5.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   5.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   5.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  11.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  11.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  10.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  10.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  10.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   2.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   2.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   2.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   2.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   2.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   5.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   5.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   5.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   5.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   5.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  10.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  10.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  10.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  11.1s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  10.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   2.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   2.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   2.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   2.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   2.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   5.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   5.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   5.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   5.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   5.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  11.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  11.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  11.1s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  11.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  11.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   3.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   3.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   3.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   3.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   3.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   8.1s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   8.1s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   7.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   7.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   7.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  15.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  15.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  15.1s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  14.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  14.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   3.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   3.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   3.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   3.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   3.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   7.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   8.1s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   7.3s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   7.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   8.1s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  15.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  14.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  15.2s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  15.7s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  15.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   3.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   3.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   3.6s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   3.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   3.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   8.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   7.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   7.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   7.0s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   6.4s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  15.5s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  15.8s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  16.1s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  13.9s\n",
      "[CV] END max_depth=3, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  14.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   5.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   5.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   6.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   5.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   5.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  12.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  12.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  12.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  11.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  24.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  25.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  24.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  23.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  25.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   6.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   5.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   5.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   5.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   5.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  13.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  12.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  11.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  11.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  12.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  24.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  24.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  24.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  25.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  22.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   5.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   5.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   6.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   5.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   6.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  12.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  12.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  12.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  12.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  12.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  25.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  24.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  24.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  23.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  24.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   6.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   5.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   5.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   6.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   6.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  12.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  12.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  12.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  11.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  12.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  25.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  25.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  24.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  26.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  25.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   5.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   6.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   6.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   6.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   5.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  12.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  13.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  13.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  13.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  12.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  24.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  17.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  18.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  17.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  19.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   6.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   5.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   5.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   5.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   6.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  12.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  12.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  12.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  11.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  13.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  24.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  23.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  24.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  25.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  27.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   6.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   6.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   6.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   5.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   6.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  12.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  11.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  10.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  11.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  12.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  26.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  26.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  26.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  25.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  23.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   5.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   5.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   6.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   5.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   5.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  12.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  11.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  13.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  12.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  11.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  24.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  26.8s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  24.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  25.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  23.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   6.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   6.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   6.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   6.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   6.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  12.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  13.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  13.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  12.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  12.3s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  22.9s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  23.7s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  18.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  23.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  23.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   8.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   8.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   8.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   8.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   8.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  16.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  17.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  16.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  15.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  16.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  33.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  35.4s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  36.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  31.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  26.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   9.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   8.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   9.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   7.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   5.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  20.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  18.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  35.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  33.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  34.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  33.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  35.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   8.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   8.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   8.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   8.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   8.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  17.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  16.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  18.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  17.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  16.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  31.4s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  33.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  32.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  31.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  33.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   7.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   8.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   8.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   7.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   7.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  15.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  16.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  16.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  15.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  15.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  31.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  31.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  32.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  31.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  31.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   8.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   7.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   7.4s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   7.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   7.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  16.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  15.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  15.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  16.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  15.4s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  31.4s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  31.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  33.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  30.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  34.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   9.4s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   9.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   9.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   8.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   9.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  17.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  16.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  16.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  17.4s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  18.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  35.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  34.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  36.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  33.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  34.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   8.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   8.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   8.4s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   8.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   8.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  17.4s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  13.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  12.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  13.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  12.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  25.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  25.2s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  25.4s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  24.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  24.4s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   6.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   5.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   5.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   5.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   5.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  11.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  11.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  11.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  11.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  12.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  27.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  24.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  25.4s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  25.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  24.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   6.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   6.4s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   5.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   6.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   6.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  12.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  12.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  12.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  12.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  12.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  26.3s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  25.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  24.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  25.9s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  26.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   7.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   8.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   7.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   7.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   7.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  15.4s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  16.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  16.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  15.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  15.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  31.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  31.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  30.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  29.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  31.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   7.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   7.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   7.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   7.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   7.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  15.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  15.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  15.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  30.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  31.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  32.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  31.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  31.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   7.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   7.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   8.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   8.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   8.4s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  17.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  17.4s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  16.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  20.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  16.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  34.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  37.4s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  39.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  40.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  37.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=  11.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=  10.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=  10.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=  10.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=  10.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  21.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  21.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  19.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  21.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  20.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  36.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  41.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  41.4s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  40.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  41.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=  11.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=  10.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=  11.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=  10.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=  11.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  21.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  16.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  22.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  15.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  14.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  30.4s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  30.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  30.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  29.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  30.4s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   7.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   7.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   7.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   7.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   7.4s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  15.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  14.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  15.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  14.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  14.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  29.4s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  29.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  31.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  35.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  39.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=  10.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   9.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=  10.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   9.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   7.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  14.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  16.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  15.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  16.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  17.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  38.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  39.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  38.4s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  39.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  38.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   9.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   9.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=  10.4s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=  10.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   9.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  18.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  20.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  19.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  19.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  20.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  38.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  40.8s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  39.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  39.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  39.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   9.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   9.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=  10.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   9.9s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=  10.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  18.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  20.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  19.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  18.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  20.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  40.5s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  38.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  39.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  39.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  39.3s\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END .........................shrinkage=None, solver=svd; total time=   0.1s\n",
      "[CV] END .........................shrinkage=None, solver=svd; total time=   0.0s\n",
      "[CV] END .........................shrinkage=None, solver=svd; total time=   0.0s\n",
      "[CV] END .........................shrinkage=None, solver=svd; total time=   0.1s\n",
      "[CV] END .........................shrinkage=None, solver=svd; total time=   0.0s\n",
      "[CV] END .......................shrinkage=None, solver=eigen; total time=   0.0s\n",
      "[CV] END .......................shrinkage=None, solver=eigen; total time=   0.0s\n",
      "[CV] END .......................shrinkage=None, solver=eigen; total time=   0.0s\n",
      "[CV] END .......................shrinkage=None, solver=eigen; total time=   0.0s\n",
      "[CV] END .......................shrinkage=None, solver=eigen; total time=   0.0s\n",
      "[CV] END .........................shrinkage=auto, solver=svd; total time=   0.0s\n",
      "[CV] END .........................shrinkage=auto, solver=svd; total time=   0.0s\n",
      "[CV] END .........................shrinkage=auto, solver=svd; total time=   0.0s\n",
      "[CV] END .........................shrinkage=auto, solver=svd; total time=   0.0s\n",
      "[CV] END .........................shrinkage=auto, solver=svd; total time=   0.0s\n",
      "[CV] END .......................shrinkage=auto, solver=eigen; total time=   0.0s\n",
      "[CV] END .......................shrinkage=auto, solver=eigen; total time=   0.0s\n",
      "[CV] END .......................shrinkage=auto, solver=eigen; total time=   0.0s\n",
      "[CV] END .......................shrinkage=auto, solver=eigen; total time=   0.0s\n",
      "[CV] END .......................shrinkage=auto, solver=eigen; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=0.1, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=0.1, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=0.1, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=0.1, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=0.1, solver=svd; total time=   0.0s\n",
      "[CV] END ........................shrinkage=0.1, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=0.1, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=0.1, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=0.1, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=0.1, solver=eigen; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=0.5, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=0.5, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=0.5, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=0.5, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=0.5, solver=svd; total time=   0.0s\n",
      "[CV] END ........................shrinkage=0.5, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=0.5, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=0.5, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=0.5, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=0.5, solver=eigen; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=1.0, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=1.0, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=1.0, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=1.0, solver=svd; total time=   0.0s\n",
      "[CV] END ..........................shrinkage=1.0, solver=svd; total time=   0.0s\n",
      "[CV] END ........................shrinkage=1.0, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=1.0, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=1.0, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=1.0, solver=eigen; total time=   0.0s\n",
      "[CV] END ........................shrinkage=1.0, solver=eigen; total time=   0.0s\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.5; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.7; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.5; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.5; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.2s\n",
      "Model Report: [{'model': SVC(C=10, gamma=0.01), 'best_params': {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}, 'accuracy': 0.8140147523709168, 'f1': 0.8119339371337239, 'sensitivity': 0.8171581769436997, 'specificity': 0.8109787674779907, 'precision': 0.806776071995765}, {'model': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), 'best_params': {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300, 'subsample': 0.7}, 'accuracy': 0.804004214963119, 'f1': 0.8014941302027748, 'sensitivity': 0.8053619302949062, 'specificity': 0.8026929052304506, 'precision': 0.7976633032395114}, {'model': KNeighborsClassifier(algorithm='ball_tree', n_neighbors=9, weights='distance'), 'best_params': {'algorithm': 'ball_tree', 'n_neighbors': 9, 'p': 2, 'weights': 'distance'}, 'accuracy': 0.7850368809272918, 'f1': 0.7869451697127937, 'sensitivity': 0.8080428954423593, 'specificity': 0.7628171931641636, 'precision': 0.7669211195928753}, {'model': RandomForestClassifier(max_depth=9, min_samples_leaf=4, n_estimators=200), 'best_params': {'max_depth': 9, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}, 'accuracy': 0.7805584826132771, 'f1': 0.7796879132504627, 'sensitivity': 0.7903485254691689, 'specificity': 0.7711030554117038, 'precision': 0.7693110647181628}, {'model': LogisticRegression(C=0.1, penalty=None, solver='newton-cholesky'), 'best_params': {'C': 0.1, 'penalty': None, 'solver': 'newton-cholesky'}, 'accuracy': 0.7766069546891464, 'f1': 0.7716747442110932, 'sensitivity': 0.7683646112600536, 'specificity': 0.7845675815639565, 'precision': 0.775013520822066}, {'model': LinearDiscriminantAnalysis(), 'best_params': {'shrinkage': None, 'solver': 'svd'}, 'accuracy': 0.7763435194942044, 'f1': 0.771343926743873, 'sensitivity': 0.767828418230563, 'specificity': 0.7845675815639565, 'precision': 0.7748917748917749}]\n"
     ]
    }
   ],
   "source": [
    "# Define the list of models and their respective hyperparameter grids\n",
    "models = [\n",
    "    SVC(),\n",
    "    LogisticRegression(), \n",
    "    KNeighborsClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    XGBClassifier()\n",
    "    ] \n",
    "        \n",
    "\n",
    "param_grids = [\n",
    "    {'kernel':('linear', 'rbf'), 'C':[0.1, 1, 10], 'gamma':[0.001, 0.01, 0.1]},\n",
    "    {'penalty' : ['l1', 'l2', 'elasticnet', None], 'C':[0.1, 1, 10], 'solver': ['lbfgs', 'newton-cholesky', 'sag', 'saga']},\n",
    "    {'n_neighbors': [3, 5, 7, 9], 'weights' : ['uniform', 'distance'], 'algorithm': ['ball_tree', 'kd_tree', 'brute'], 'p': [1, 2]}, \n",
    "    {'n_estimators' : [50, 100, 200], 'max_depth': [3, 5, 7, 9], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}, # still takes a lot of time\n",
    "    {'solver': ['svd', 'eigen'], 'shrinkage': [None, 'auto', 0.1, 0.5, 1.0]},\n",
    "    {'max_depth': [4, 5], 'learning_rate': [0.1, 0.01], 'n_estimators': [200, 300], 'subsample': [0.5, 0.7, 1.0], 'colsample_bytree': [0.8, 0.9, 1.0]}\n",
    "]\n",
    "\n",
    "# Call the function to compare models and get the best one\n",
    "models_report = compare_models(models, param_grids, X_train_normalized, y_train_encoded, X_val_normalized, y_val_encoded, scoring_metric='accuracy', cv=5)\n",
    "\n",
    "# Save the best model to a file\n",
    "# best_model_filename = ROOT_PATH/'best_model.pkl'\n",
    "# with open(best_model_filename, 'wb') as file:\n",
    "#     pickle.dump(best_model, file)\n",
    "\n",
    "print(\"Model Report:\", models_report)\n",
    "# print(\"Best Score:\", best_score)\n",
    "# print(\"Best Params:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': SVC(C=10, gamma=0.01),\n",
       "  'best_params': {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  'accuracy': 0.8140147523709168,\n",
       "  'f1': 0.8119339371337239,\n",
       "  'sensitivity': 0.8171581769436997,\n",
       "  'specificity': 0.8109787674779907,\n",
       "  'precision': 0.806776071995765},\n",
       " {'model': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bynode=None,\n",
       "                colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "                enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "                gamma=None, grow_policy=None, importance_type=None,\n",
       "                interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "                num_parallel_tree=None, random_state=None, ...),\n",
       "  'best_params': {'colsample_bytree': 1.0,\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'n_estimators': 300,\n",
       "   'subsample': 0.7},\n",
       "  'accuracy': 0.804004214963119,\n",
       "  'f1': 0.8014941302027748,\n",
       "  'sensitivity': 0.8053619302949062,\n",
       "  'specificity': 0.8026929052304506,\n",
       "  'precision': 0.7976633032395114},\n",
       " {'model': KNeighborsClassifier(algorithm='ball_tree', n_neighbors=9, weights='distance'),\n",
       "  'best_params': {'algorithm': 'ball_tree',\n",
       "   'n_neighbors': 9,\n",
       "   'p': 2,\n",
       "   'weights': 'distance'},\n",
       "  'accuracy': 0.7850368809272918,\n",
       "  'f1': 0.7869451697127937,\n",
       "  'sensitivity': 0.8080428954423593,\n",
       "  'specificity': 0.7628171931641636,\n",
       "  'precision': 0.7669211195928753},\n",
       " {'model': RandomForestClassifier(max_depth=9, min_samples_leaf=4, n_estimators=200),\n",
       "  'best_params': {'max_depth': 9,\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200},\n",
       "  'accuracy': 0.7805584826132771,\n",
       "  'f1': 0.7796879132504627,\n",
       "  'sensitivity': 0.7903485254691689,\n",
       "  'specificity': 0.7711030554117038,\n",
       "  'precision': 0.7693110647181628},\n",
       " {'model': LogisticRegression(C=0.1, penalty=None, solver='newton-cholesky'),\n",
       "  'best_params': {'C': 0.1, 'penalty': None, 'solver': 'newton-cholesky'},\n",
       "  'accuracy': 0.7766069546891464,\n",
       "  'f1': 0.7716747442110932,\n",
       "  'sensitivity': 0.7683646112600536,\n",
       "  'specificity': 0.7845675815639565,\n",
       "  'precision': 0.775013520822066},\n",
       " {'model': LinearDiscriminantAnalysis(),\n",
       "  'best_params': {'shrinkage': None, 'solver': 'svd'},\n",
       "  'accuracy': 0.7763435194942044,\n",
       "  'f1': 0.771343926743873,\n",
       "  'sensitivity': 0.767828418230563,\n",
       "  'specificity': 0.7845675815639565,\n",
       "  'precision': 0.7748917748917749}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, gamma=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, gamma=0.01)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10, gamma=0.01)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = models_report[0]['model']\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# = {'kernel':('linear', 'rbf', 'sigmoid', 'poly'), 'C':[0.1, 1, 10, 100, 1000], 'gamma':[0.001, 0.0001]}\n",
    "#svc = SVC()\n",
    "\n",
    "# Create a GridSearchCV object with a classifier and the parameter grid\n",
    "#grid_search = GridSearchCV(estimator=svc, param_grid=parameters, cv=10, verbose=10)\n",
    "\n",
    "# Fit the grid search to your training data\n",
    "#grid_search.fit(X_train_normalized, y_train_encoded)\n",
    "\n",
    "# Get the best hyperparameters and the best model\n",
    "#best_params = grid_search.best_params_\n",
    "#best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_val_normalized)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_val_encoded, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(len(thresholds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7763435194942044\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val_encoded, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model_filename = ROOT_PATH/'best_model.pkl'\n",
    "# # Load the saved model from a file\n",
    "# with open(best_model_filename, 'rb') as file:\n",
    "#     loaded_model = pickle.load(file)\n",
    "\n",
    "# # Now you can use loaded_model to make predictions on new samples\n",
    "# X_pred = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
